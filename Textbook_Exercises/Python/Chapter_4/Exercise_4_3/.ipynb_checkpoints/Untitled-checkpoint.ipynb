{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-02269a1e2369>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-02269a1e2369>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    function softmax_grad_demo_hw()\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "function softmax_grad_demo_hw()\n",
    "\n",
    "% softmax_grad_demo_hw runs the softmax model on a separable two \n",
    "% class dataset consisting of two dimensional data features.\n",
    "\n",
    "% This file is associated with the book\n",
    "% \"Machine Learning Refined\", Cambridge University Press, 2016.\n",
    "% by Jeremy Watt, Reza Borhani, and Aggelos Katsaggelos.\n",
    "\n",
    "\n",
    "%%% load data %%%\n",
    "[X,y] = load_data();\n",
    "\n",
    "%%% run gradient descent %%%\n",
    "X_tilde = [ones(size(X,1),1) X]';  % use compact notation\n",
    "w0 = randn(3,1);              % random initial point\n",
    "L = norm(X_tilde)^2;               % Lipschitz constant of softmax cost\n",
    "alpha = 4/L;                 % fixed steplength via Lipschitz constant - guaranteed to make grad descent converge\n",
    "w = softmax_grad(X_tilde,y,w0,alpha);\n",
    "\n",
    "%%% plot everything, pts and lines %%%\n",
    "plot_all(X',y,w);\n",
    "\n",
    "\n",
    "%%%%%%%%%%%%%%%%% functions %%%%%%%%%%%%%%%\n",
    "%%% gradient descent function for softmax cost/logistic regression %%%\n",
    "function w = softmax_grad(X,y,w,alpha)\n",
    "  \n",
    "    % Initializations \n",
    "    H = diag(y)*X';\n",
    "    iter = 1;\n",
    "    max_its = 30000;\n",
    "    grad = 1;\n",
    "    \n",
    "    while  norm(grad) > 10^-12 && iter < max_its\n",
    "        % compute gradient\n",
    "        grad = - (H'*(sigmoid(-H*w)));\n",
    "        w = w - alpha*grad;\n",
    "\n",
    "        % update iteration count\n",
    "        iter = iter + 1;\n",
    "    end\n",
    "end\n",
    "\n",
    "%%% sigmoid for softmax/logistic regression minimization %%%\n",
    "function y = sigmoid(z)\n",
    "y = 1./(1+exp(-z));\n",
    "end\n",
    "\n",
    "%%% plots everything %%%\n",
    "function plot_all(X,y,w)\n",
    "    red = [1 0 .4];\n",
    "    blue =  [ 0 .4 1];\n",
    "\n",
    "    % plot points \n",
    "    ind = find(y == 1);\n",
    "    scatter(X(1,ind),X(2,ind),'Linewidth',2,'Markeredgecolor',blue,'markerFacecolor','none');\n",
    "    hold on\n",
    "    ind = find(y == -1);\n",
    "    scatter(X(1,ind),X(2,ind),'Linewidth',2,'Markeredgecolor',red,'markerFacecolor','none');\n",
    "    hold on\n",
    "\n",
    "    % plot separator\n",
    "    s =[0:0.01:1 ];\n",
    "    plot (s,(-w(1)-w(2)*s)/w(3),'m','linewidth',2);\n",
    "    \n",
    "    % clean up plot and add info labels\n",
    "    set(gcf,'color','w');\n",
    "    axis square\n",
    "    box off\n",
    "    axis([0 1 0 1])\n",
    "    xlabel('x_1','Fontsize',14)\n",
    "    ylabel('x_2  ','Fontsize',14)\n",
    "    set(get(gca,'YLabel'),'Rotation',0)\n",
    "end\n",
    "\n",
    "%%% loads data %%%\n",
    "function [X,y] = load_data()\n",
    "    data = csvread('imbalanced_2class.csv');\n",
    "    X = data(:,1:end-1);\n",
    "    y = data(:,end);\n",
    "end\n",
    "\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# softmax_grad_demo_hw runs the softmax model on a separable two \n",
    "# class dataset consisting of two dimensional data features.\n",
    "\n",
    "# This file is associated with the book\n",
    "# \"Machine Learning Refined\", Cambridge University Press, 2016.\n",
    "# by Jeremy Watt, Reza Borhani, and Aggelos Katsaggelos.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# sigmoid for softmax/logistic regression minimization\n",
    "def sigmoid(z): \n",
    "    y = 1./float(1+np.exp(-z))\n",
    "    return y\n",
    "    \n",
    "# import training data \n",
    "def load_data(csvname):\n",
    "    # load in dataframe\n",
    "    all_data = np.array(np.genfromtxt(csvname,delimiter = ','))\n",
    "\n",
    "    # grab training data and labels\n",
    "    X = all_data[:,:-1]      \n",
    "    y = all_data[:,-1]\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = load_data('imbalanced_2class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plots everything \n",
    "def plot_all(X,y,w):\n",
    "    # custom colors for plotting points\n",
    "    red = [1,0,0.4]  \n",
    "    blue = [0,0.4,1]\n",
    "    \n",
    "    # scatter plot points\n",
    "    fig = plt.figure(figsize = (4,4))\n",
    "    ind = np.argwhere(y==1)\n",
    "    ind = [s[0] for s in ind]\n",
    "    plt.scatter(X[ind,0],X[ind,1],y[ind],color = red,edgecolor = 'k',linewidth = 4,s = 50)\n",
    "    ind = np.argwhere(y==-1)\n",
    "    ind = [s[0] for s in ind]\n",
    "    print ind\n",
    "    plt.scatter(X[ind,0],X[ind,1],y[ind],color = 'b',edgecolor = 'k',linewidth = 4)\n",
    "    plt.grid('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() got multiple values for keyword argument 's'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-1cb3f948130a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-102-b7f0fb92297d>\u001b[0m in \u001b[0;36mplot_all\u001b[0;34m(X, y, w)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medgecolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'k'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: scatter() got multiple values for keyword argument 's'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11602a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_all(X,y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "ind = np.argwhere(y==-1)\n",
    "ind = [s[0] for s in ind]\n",
    "print ind\n",
    "print y[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-82-0d95af91a53d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-82-0d95af91a53d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    function plot_all(X,y,w)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "function plot_all(X,y,w)\n",
    "    red = [1 0 .4];\n",
    "    blue =  [ 0 .4 1];\n",
    "\n",
    "    % plot points \n",
    "    ind = find(y == 1);\n",
    "    scatter(X(1,ind),X(2,ind),'Linewidth',2,'Markeredgecolor',blue,'markerFacecolor','none');\n",
    "    hold on\n",
    "    ind = find(y == -1);\n",
    "    scatter(X(1,ind),X(2,ind),'Linewidth',2,'Markeredgecolor',red,'markerFacecolor','none');\n",
    "    hold on\n",
    "\n",
    "    % plot separator\n",
    "    s =[0:0.01:1 ];\n",
    "    plot (s,(-w(1)-w(2)*s)/w(3),'m','linewidth',2);\n",
    "    \n",
    "    % clean up plot and add info labels\n",
    "    set(gcf,'color','w');\n",
    "    axis square\n",
    "    box off\n",
    "    axis([0 1 0 1])\n",
    "    xlabel('x_1','Fontsize',14)\n",
    "    ylabel('x_2  ','Fontsize',14)\n",
    "    set(get(gca,'YLabel'),'Rotation',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

# Machine Learning Refined IPython notebooks, Python and MATLAB files

Click [![Binder](http://mybinder.org/badge.svg)](http://mybinder.org:/repo/jermwatt/mlrefined) to launch a LIVE instance of the IPython notebooks in this repo.  

This repository contains various supplementary IPython notebooks, Python and MATLAB files, and Powerpoint presentations associated with the textbook Machine Learning Refined (Cambridge University Press). Visit [http://www.mlrefined.com](www.mlrefined.com) for free chapter downloads and tutorials, and [our Amazon site here for details regarding a hard copy of the text](https://www.amazon.com/Machine-Learning-Refined-Foundations-Applications/dp/1107123526/ref=sr_1_1?ie=UTF8&qid=1471025359&sr=8-1&keywords=machine+learning+refined).

**NOTE: Python version 2.7 is used for all Python based exercises.**

Short video tutorials illustrating critical ML topics using the Python / MATLAB files here may be found below.
## Video tutorials on gradient descent and Newton's method

Below is a video tutorial illustrating how gradient descent works via use of the demo code (convex_grad_surrogate and nonconvex_grad_surrogate, which you may find here) - these illustrate the basic concepts underlying gradient descent applied to minimizing both convex and nonconvex functions. Some principles from the chapter are briefly described before jumping into the code.

[![Demo Doccou alpha](https://j.gifs.com/o2AJjA.gif)](https://youtu.be/yy1otucCYVM)

Below is a video tutorial illustrating how Newton's method works via use of the demo code (convex_newton_surrogate and nonconvex_newton_surrogate, which you may find here) - these illustrate the basic concepts underlying Newton's method applied to minimizing both convex and nonconvex functions. Some principles from the chapter are briefly described before jumping into the code.

[![Demo Doccou alpha](https://j.gifs.com/zpql9q.gif)](https://www.youtube.com/watch?v=LLc-N3jgj7U)

## Video tutorial on regression and L2 regularization

Below is a video tutorial illustrating how L2 regularization convexifies nonconvex cost functions, thereby making minimization of such functions easier.  The code (l2reg_logistic, which you may find here) shows the result of applying L2 regularization to a nonconvex form of logistic regression on a simple dataset, as well as the resulting convexificaation of this cost function due to regularization.   Again, some principles from the chapter - which is available for download at www.mlrefined.com -  are briefly described before jumping into the code.

[![Demo Doccou alpha](https://j.gifs.com/AD8OG1.gif)](https://youtu.be/ON_7wm-Qe6c)


## Chapter 4 demos on two class logistic regression and support vector machines, as well as multi-class one-versus-all and multiclass softmax / logistic regression

Two class classification with logistic regression:

![alt tag](https://raw.githubusercontent.com/jermwatt/mlrefined/master/Chap-4/2class-classification/logistic_example.png)

Multiclass classification with One-versus-All classification

![alt tag](https://raw.githubusercontent.com/jermwatt/mlrefined/master/Chap-4/multi-class/multiclass.gif)


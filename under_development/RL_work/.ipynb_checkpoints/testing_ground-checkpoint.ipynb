{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "class my_gridworld_2():\n",
    "    \n",
    "    def __init__(self,**args):\n",
    "                \n",
    "        ### initialize global containers and variables\n",
    "        # initialize containers for grid, hazard locations, agent and goal locations, etc.,\n",
    "        self.grid = []\n",
    "        self.hazards = []\n",
    "        self.agent = []\n",
    "        self.goal = []\n",
    "        \n",
    "        # initialize global variables e.g., height and width of gridworld, hazard penalty value\n",
    "        self.width = 0\n",
    "        self.height = 0\n",
    "        self.hazard_penalty = 0\n",
    "        \n",
    "        ### check for optional arguments controlling size of gridworld, number/placement/value of hazards.  If no args given go to default.\n",
    "        # check if a pre-defined gridworld is desired\n",
    "        if \"world\" in args:\n",
    "            # small demo gridworld\n",
    "            if args['world'] == 'small demo':\n",
    "                ### initialize grid, agent, obstacles, etc.,\n",
    "                self.width = 5\n",
    "                self.height = 4\n",
    "                self.grid = np.zeros((self.height,self.width))\n",
    "\n",
    "                # initialize goal location\n",
    "                self.goal = [0,self.width-1]     # goal block\n",
    "                self.grid[self.goal[0]][self.goal[1]] = 2\n",
    "                \n",
    "                # initialize player location\n",
    "                self.player = [0,0]   # initial location player\n",
    "                self.grid[self.player[0]][self.player[1]] = 3                \n",
    "                \n",
    "                # initialize hazard locations\n",
    "                self.hazards = [[0,3],[1,3],[2,3]]  # impenetrable obstacle locations          \n",
    "                for i in range(len(self.hazards)): \n",
    "                    block = self.hazards[i]\n",
    "                    self.hazards.append(block)\n",
    "                    self.grid[block[0]][block[1]] = 1\n",
    "                                                  \n",
    "            # small random gridworld\n",
    "            if args['world'] == 'small random':\n",
    "                ### initialize locations ###\n",
    "                # initialize grid, agent, hazards, etc.,\n",
    "                self.width = 7\n",
    "                self.height = 7\n",
    "                self.grid = np.zeros((self.height,self.width))\n",
    "                            \n",
    "                # initialize goal location\n",
    "                self.goal = [0,self.width-1]     # goal block\n",
    "                self.grid[self.goal[0]][self.goal[1]] = 2\n",
    "                \n",
    "                # initialize player location\n",
    "                self.player = [0,0]   # initial location player\n",
    "                self.grid[self.player[0]][self.player[1]] = 3   \n",
    "                \n",
    "                # initialize random hazards locations\n",
    "                num_hazards = 15\n",
    "                self.hazards = []\n",
    "                inds = np.random.permutation(self.width*self.height)\n",
    "                inds = inds[:num_hazards]\n",
    "                k = 0\n",
    "                for i in range(self.height):\n",
    "                    for j in range(self.width):\n",
    "                        if k in inds: \n",
    "                            block = [i,j]\n",
    "                            if block != self.goal and block != self.player:\n",
    "                                self.hazards.append(block)\n",
    "                                self.grid[block[0]][block[1]] = 1\n",
    "                        k+=1\n",
    "            \n",
    "            # initialize a big gridworld with randomly placed hazards.  \n",
    "            if args[\"world\"] == 'big random':\n",
    "                ### initialize locations ###\n",
    "                # initialize grid, agent, hazards, etc.,\n",
    "                self.width = 20\n",
    "                self.height = 10\n",
    "                self.grid = np.zeros((self.height,self.width))\n",
    "\n",
    "                # initialize goal location\n",
    "                self.goal = [0,self.width-1]     # goal block\n",
    "                self.grid[self.goal[0]][self.goal[1]] = 2\n",
    "                \n",
    "                # initialize player location\n",
    "                self.player = [0,0]   # initial location player\n",
    "                self.grid[self.player[0]][self.player[1]] = 3   \n",
    "                \n",
    "                # initialize random hazards locations\n",
    "                num_hazards = 50\n",
    "                self.hazards = []\n",
    "                inds = np.random.permutation(self.width*self.height)\n",
    "                inds = inds[:num_hazards]\n",
    "                k = 0\n",
    "                for i in range(self.height):\n",
    "                    for j in range(self.width):\n",
    "                        if k in inds: \n",
    "                            block = [i,j]\n",
    "                            if block != self.goal and block != self.player:\n",
    "                                self.hazards.append(block)\n",
    "                                self.grid[block[0]][block[1]] = 1\n",
    "                        k+=1\n",
    "        \n",
    "            # small maze gridworld                      \n",
    "            if args[\"world\"] == 'small maze':\n",
    "                # load in preset hazard locations from csv\n",
    "                hazards = np.asarray(pd.read_csv('RL_datasets/small_maze.csv',header = None))\n",
    "                \n",
    "                ### initialize grid, agent, obstacles, etc.,            \n",
    "                self.width = 13\n",
    "                self.height = 11\n",
    "                self.grid = np.zeros((self.height,self.width))\n",
    "                \n",
    "                # initialize goal location\n",
    "                self.goal = [self.height-2, self.width-1]     # goal block\n",
    "                self.grid[self.goal[0]][self.goal[1]] = 2\n",
    "                \n",
    "                # initialize player location\n",
    "                self.player = [self.height-2, 0]   # initial location player\n",
    "                self.grid[self.player[0]][self.player[1]] = 3   \n",
    "  \n",
    "                # initialize hazards locations\n",
    "                for block in hazards: \n",
    "                    self.hazards.append(block)\n",
    "                    self.grid[block[0]][block[1]] = 1\n",
    "        \n",
    "            # big maze gridworld                      \n",
    "            if args[\"world\"] == 'big maze':\n",
    "                # load in preset hazard locations from csv\n",
    "                hazards = np.asarray(pd.read_csv('RL_datasets/big_maze.csv',header = None))\n",
    "                \n",
    "                ### initialize grid, agent, obstacles, etc.,            \n",
    "                self.width = 41\n",
    "                self.height = 15\n",
    "                self.grid = np.zeros((self.height,self.width))\n",
    "\n",
    "                # initialize goal location\n",
    "                self.goal = [self.height-2, self.width-1]     # goal block\n",
    "                self.grid[self.goal[0]][self.goal[1]] = 2\n",
    "\n",
    "                # initialize player location\n",
    "                self.player = [self.height-2, 0]   # initial location player\n",
    "                self.grid[self.player[0]][self.player[1]] = 3   \n",
    "\n",
    "                # initialize player location\n",
    "                self.player = [0,0]   # initial location player\n",
    "                self.grid[self.player[0]][self.player[1]] = 3   \n",
    "                \n",
    "                # initialize hazards locations\n",
    "                for block in hazards: \n",
    "                    self.hazards.append(block)\n",
    "                    self.grid[block[0]][block[1]] = 1\n",
    "                    \n",
    "        ### check for hazard penalty value ###\n",
    "        if \"hazard value\" in args:\n",
    "            self.hazard_penalty = args['hazard value']\n",
    "        else:\n",
    "            self.hazard_penalty = max(self.width,self.height)        \n",
    "        \n",
    "        ### initialize state index, Q matrix, and action choices ###\n",
    "        # index states for Q matrix\n",
    "        self.states = []\n",
    "        for i in range(self.height):\n",
    "            for j in range(self.width):\n",
    "                block = [i,j]\n",
    "                self.states.append(str(i) + str(j))\n",
    "        \n",
    "        # initialize action choices\n",
    "        self.action_choices = [[-1,0],[1,0],[0,-1],[0,1]]\n",
    "        \n",
    "        # initialize Q^* matrix\n",
    "        self.Q_star = np.zeros((self.width*self.height,len(self.action_choices)))\n",
    "\n",
    "        ### create custom colormap for gridworld plotting ###\n",
    "        vmax = 3.0\n",
    "        self.my_cmap = LinearSegmentedColormap.from_list('mycmap', [(0 / vmax, [0.9,0.9,0.9]),\n",
    "                                                        (1 / vmax, [1,0.5,0]),\n",
    "                                                        (2 / vmax, 'lime'),\n",
    "                                                        (3 / vmax, 'blue')]\n",
    "                                                        )\n",
    "        \n",
    "    ### world coloring function ###\n",
    "    def color_gridworld(self,ax):\n",
    "        # plot gridworld\n",
    "        ax.pcolormesh(self.grid,edgecolors = 'k',linewidth = 0.01,cmap = self.my_cmap)\n",
    "\n",
    "        # clean up plot\n",
    "        ax.axis('off')\n",
    "        ax.set_xlim(-0.1,self.width + 1.1);\n",
    "        ax.set_ylim(-0.1,self.height + 1.1);        \n",
    "        \n",
    "    ## Q-learning function\n",
    "    def qlearn(self,num_train_animate):\n",
    "        # parameters for the qlearning \n",
    "        gamma = 0.8\n",
    "        num_episodes = 300\n",
    "        num_complete = 0\n",
    "        \n",
    "        # loop over episodes, for each run simulation and update Q\n",
    "        for n in range(num_episodes):\n",
    "            # pick initialization \n",
    "            obstical_free = 0\n",
    "            loc = [np.random.randint(self.grid.height),np.random.randint(self.grid.width)]\n",
    "           \n",
    "            # update Q matrix while loc != goal\n",
    "            steps = 0  # step counter\n",
    "            max_steps = 10*self.grid.width*self.grid.height  # maximum number of steps per episode\n",
    "            while steps < max_steps:    \n",
    "                # when you reach the goal end current episode\n",
    "                if loc == self.goal:\n",
    "                    break\n",
    "                    \n",
    "                ### choose action - left = 0, right = 1, up = 2, down = 3\n",
    "                k = np.random.randint(len(self.action_choices))  \n",
    "                loc2 = [sum(x) for x in zip(loc, self.action_choices[k])] \n",
    "                ind_old = self.states.index(str(loc[0]) + str(loc[1]))\n",
    "\n",
    "                ### set reward    \n",
    "                # is the new location just a regular square?  Than small negative reward\n",
    "                r_k = int(-1)\n",
    "\n",
    "                # if new state is hazard penalize with medium negative value - this needs to be set properly if you're trying to prove a point i.e., that a trained agent won't walk over one of these unless going around costs more\n",
    "                if loc2 in self.hazards:\n",
    "                    r_k = self.hazard_penalty\n",
    "\n",
    "                # if new state is goal set reward of 0\n",
    "                if loc2 == self.goal:\n",
    "                    r_k = int(0)\n",
    "                    \n",
    "                # if new state is outside of boundaries of grid world penalize set reward to small negative value (like -1) and do not move\n",
    "                if loc2[0] > self.grid.height-1 or loc2[0] < 0 or loc2[1] > self.grid.width-1 or loc2[1] < 0:  \n",
    "                    r_k = int(-1)\n",
    "                    loc2 = loc\n",
    "                \n",
    "                ### Update Q\n",
    "                ind_new = self.states.index(str(loc2[0]) + str(loc2[1]))\n",
    "                self.Q_star[ind_old,k] = r_k + gamma*max(self.Q_star[ind_new,:])\n",
    "                    \n",
    "                # update current location of player to one we just moved too (or stay still if grid world boundary met)\n",
    "                self.player = loc2\n",
    "                loc = loc2\n",
    "                \n",
    "                # the next few lines just animate the first few steps during the first few episodes\n",
    "                if n < num_train_animate and steps < 200:\n",
    "                    self.color_grid()\n",
    "                    time.sleep(0.1)\n",
    "                    display.clear_output(wait=True)\n",
    "                    \n",
    "                # update counter\n",
    "                steps+=1\n",
    "        \n",
    "            # pause briefly between first few episodes to show user cutoff\n",
    "            if n < num_train_animate:\n",
    "                time.sleep(1)\n",
    "                print 'finished episode, animating next episode'\n",
    "                time.sleep(1)\n",
    "            if n == num_train_animate:\n",
    "                print 'continuing with remaining episodes without animation...'\n",
    "                \n",
    "        print 'q-learning process complete'\n",
    "                \n",
    "    # print out\n",
    "    def show_qmat(self):        \n",
    "        states_print = []\n",
    "        for i in range(len(self.states)):\n",
    "            s = str(self.states[i])\n",
    "            t = str('(') + s[0] + ',' + s[1] + str(')')\n",
    "            states_print.append(t)\n",
    "            \n",
    "        df = pd.DataFrame(self.Q_star,columns=['up','down','left','right'], index=states_print)\n",
    "        print df.round(3)             \n",
    "            \n",
    "    # animate the testing phase based on completed Q-learning cycle\n",
    "    def animate_testing_phase(self,loc):\n",
    "        # show movement based on an initial \n",
    "        self.player = loc # initial agent location\n",
    "\n",
    "        # if you chose an invalid starting position, break out and try again\n",
    "        if  loc == self.goal or loc[0] > self.grid.height-1 or loc[0] < 0 or loc[1] > self.grid.width-1 or loc[1] < 0:\n",
    "            print 'initialization is outside of gridworld or is goal, try again'\n",
    "        else:  \n",
    "            # now use the learned Q* matrix to run from any (valid) initial point to the goal\n",
    "            self.color_grid()\n",
    "            time.sleep(0.3)\n",
    "            display.clear_output(wait=True)\n",
    "            count = 0\n",
    "            max_count = self.grid.width*self.grid.height\n",
    "            while count < max_count:\n",
    "                # find next state using max Q* value\n",
    "                ind_old = self.states.index(str(self.player[0]) + str(self.player[1]))\n",
    "                \n",
    "                # find biggest value in Q* and determine block location\n",
    "                action_ind = np.argmax(self.Q_star[ind_old,:])\n",
    "                action = self.action_choices[action_ind]\n",
    "                \n",
    "                # move player to new location and recolor - if you move out of gridworld halt and report this to user\n",
    "                new_loc = [sum(x) for x in zip(self.player,action)] \n",
    "                \n",
    "                if new_loc[0] > self.grid.height-1 or new_loc[0] < 0 or new_loc[1] > self.grid.width-1 or new_loc[1] < 0:\n",
    "                    print 'something went wrong - the player has left the gridworld arena'\n",
    "                    print \"your episodes did not the states reached by your initialization enough to train Q properly here\"\n",
    "                    print \"this is likely because you didn't traiin long enough - up the number of steps / episodes and try again\"\n",
    "                    \n",
    "                self.player = new_loc\n",
    "                \n",
    "                # clear current screen for next step\n",
    "                self.color_grid()\n",
    "                time.sleep(0.2)\n",
    "                if self.player == self.goal:\n",
    "                    break\n",
    "                display.clear_output(wait=True)\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = my_gridworld_2(world = 'big maze')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAADyCAYAAACrrgQOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABoxJREFUeJzt3UGOo0gQQFF7NKfwaeu0dQ33YlRLNCZbQNTnvTV0mKSk\n/hKLeL7f7wcAQNU/V/8AAIAjiR0AIE3sAABpYgcASBM7AECa2AEA0sQOAJAmdgCANLEDAKSJHQAg\nTewAAGliBwBIEzsAQJrYAQDSxA4AkCZ2AIA0sQMApIkdACBN7AAAaWIHAEgTOwBAmtgBANL+vfoH\n/Hg+n++rfwMAcI33+/086t8eEzuPx+Px/tp3/fNr3z17rzfDDDN+34yVe8www4zrZxzJZywAIE3s\nAABpYgcASBM7AECa2AEA0sQOAJAmdgCANLEDAKSJHQAgTewAAGnP93vGSiq7sQDgvm6zG+vx2Ns7\nz8f39/fHV79er13Xr9xTmrGyC2Xic1RmVN7H0c+x+rvuPGPvDiPPccz1tRm7/ks/LHP+4zMWAJAm\ndgCANLEDAKSJHQAgTewAAGliBwBIEzsAQJrYAQDSxA4AkCZ2AIA0sQMApFkECgBc7jaLQM9YdLgy\nY+9yuakznNXn91TOatqSzjMXgZ6xFLLy9z7xrCozvPPPZxzJZywAIE3sAABpYgcASBM7AECa2AEA\n0sQOAJAmdgCANLEDAKSJHQAgTewAAGl2YwEAl7Mba8PEvTyv12tph8jEGZWzqjyHs9p3zxm7f6Y9\n++QZE3cx3fmsJj7HkXzGAgDSxA4AkCZ2AIA0sQMApIkdACBN7AAAaWIHAEgTOwBAmtgBANLEDgCQ\nJnYAgDSLQAGAy1kEumHqItCVGXsXpk2d4X2YcfWMlXvMmDfjjMWTnmPWjCP5jAUApIkdACBN7AAA\naWIHAEgTOwBAmtgBANLEDgCQJnYAgDSxAwCkiR0AIM1uLADgcnZjbZi6i2llF8pdZ3gfn1/vrH73\n7zLj+Bln7K3yHJ/fYzcWAMBJxA4AkCZ2AIA0sQMApIkdACBN7AAAaWIHAEgTOwBAmtgBANLEDgCQ\nJnYAgDSLQAGAy1kEuuGsRaB7l5mZYcYn90xcBDp1xtR3eNcZU5dbTpxReR9nPMeRfMYCANLEDgCQ\nJnYAgDSxAwCkiR0AIE3sAABpYgcASBM7AECa2AEA0sQOAJAmdgCANItAAYDLWQS6YWUJ4crCtIkz\nnNWsGZX3MXURaOXv5M4zJi63vPNZTXyOI/mMBQCkiR0AIE3sAABpYgcASBM7AECa2AEA0sQOAJAm\ndgCANLEDAKSJHQAgzW4sAOBydmNtOGsvz979HlOfo3JWlfdROatp7+PxWNvLM/XZzfjdM6buxpp4\nVkfyGQsASBM7AECa2AEA0sQOAJAmdgCANLEDAKSJHQAgTewAAGliBwBIEzsAQJrYAQDSLAIFAC5n\nEeiGlYWNKwvT7jqj8j4qz1GZcdYi0InPPnXGGYsnK2flfXx+j0WgAAAnETsAQJrYAQDSxA4AkCZ2\nAIA0sQMApIkdACBN7AAAaWIHAEgTOwBAmt1YAMDl7Mba8Pzad8/e63/uOWP3zxnP4azMOGLG1N1Y\nZ+wXqrxDZ2XG/11vNxYAwGBiBwBIEzsAQJrYAQDSxA4AkCZ2AIA0sQMApIkdACBN7AAAaWIHAEgT\nOwBAmkWgAMDlLALdsLKEcGWZmRnHzfDO7zfjzotAK+/QDDM+ucciUACAk4gdACBN7AAAaWIHAEgT\nOwBAmtgBANLEDgCQJnYAgDSxAwCkiR0AIM1uLADgcnZjbVjZk7QyY+9+j6kzpu0wmjyj8s7vOGPl\nnrNmnLFfyFkd85tW7pm8c23iWR3JZywAIE3sAABpYgcASBM7AECa2AEA0sQOAJAmdgCANLEDAKSJ\nHQAgTewAAGliBwBIswgUALicRaAbVpZCrixMm7jcsvIclbMyY86Mqb9rdcYZSyGd1TG/y3N8fr1F\noAAAf0HsAABpYgcASBM7AECa2AEA0sQOAJAmdgCANLEDAKSJHQAgTewAAGl2YwEAl7Mba8Pza989\ne683wwwzft+MlXvMMMOM62ccyWcsACBN7AAAaWIHAEgTOwBAmtgBANLEDgCQJnYAgDSxAwCkiR0A\nIE3sAABpYgcASLMIFAC43JGLQMfEDgDAEXzGAgDSxA4AkCZ2AIA0sQMApIkdACBN7AAAaWIHAEgT\nOwBAmtgBANLEDgCQJnYAgDSxAwCkiR0AIE3sAABpYgcASBM7AECa2AEA0sQOAJAmdgCANLEDAKSJ\nHQAgTewAAGliBwBIEzsAQJrYAQDSxA4AkCZ2AIA0sQMApIkdACDtDykBWRu9oYHKAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11351ea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(figsize = (15,15))\n",
    "ax1 = fig1.add_subplot(121, aspect='equal')\n",
    "test.color_gridworld(ax1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  2.])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train q learning and lets examine the matrix as it develops\n",
    "test.qlearn(num_train_animate = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(250, 100, 0);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(0, 0, 200);\"></td></tr><tr><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(250, 100, 0);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td></tr><tr><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(250, 100, 0);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td></tr><tr><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td><td style=\"width: 25px; height: 25px; border: 3px solid white; background-color: rgb(200, 200, 200);\"></td></tr></tbody></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run testing phase\n",
    "starting_location = [1,0]\n",
    "test.animate_testing_phase(starting_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Unsupervised Learning Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.4  Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Section we discuss the fundamental linear *Recommender System*, a popular unsupervised learning framework commonly employed by businesses to help automatically recommend products and services to their customers.  From the vantage of machine learning however, the basic Recommender System detailed here is simply a slight twist on  our core unsupervised learning technique: Principal Component Analysis (PCA).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4.1 Introduction and motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender systems are heavily used in e-commerce today, providing customers with personalized recommendations for products and services by using a consumer's previous purchasing and rating history, along with those of similar customers.  For instance, a movie provider like Netflix with millions of users and tens of thousands of movies, records users' reviews and ratings (typically in the form of a number on a scale of 1-5 with 5 being the most favorable rating) in a large matrix such as the one illustrated below in the Figure. These matrices are very sparsely populated, since an individual consumer has likely rated only a small portion of the movies available. With this data available, online movie and commerce sites often use the unsupervised learning technique we discuss in this Section as their main technique for making personalized recommendations to customers regarding what they might like to watch / consume next. With the technique for producing personalized recommendations we discuss here - typically referred to as a *Recommender System* - we aim to intelligently guess the values of every missing entry in the ratings matrix (we *complete* the matrix).  Then, in order to recommend a new product to a given user, we examine our completely filled ratings matrix for products we have predicted the user would highly rate (and thus enjoy) and recommend these.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src= '../../mlrefined_images/unsupervised_images/Fig_9_11.png' width=\"100%\" height=\"auto\" alt=\"\"/>\n",
    "  <figcaption>   \n",
    "<strong>Figure 1:</strong> <em> A prototypical movie rating matrix is very sparsely populated, with each user having rated only a very small number of films. In this diagram movies are listed along rows with users along columns.  In order to properly recommend movies for users to watch we try to intelligently guess the missing values of this matrix, and then recommend movies that we predict users would highly rate (and therefore enjoy the most).\n",
    "  </em>  </figcaption> \n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "# custom libs\n",
    "from mlrefined_libraries import unsupervised_library as unsuplib\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "datapath = '../../mlrefined_datasets/unsuperlearn_datasets/'\n",
    "\n",
    "# this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4.2  Formal modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows we will use the familiar notation $\\mathbf{x}_1,...,\\mathbf{x}_P$ to denote our input data each of dimension $N$ - here $\\mathbf{x}_p$ is our $p^{th}$ user's rating vector each of which is sparsely populated.  Formally we can express the index set of entries of these ratings vectors we actually have as\n",
    "\n",
    "\\begin{equation}\n",
    "\\Omega = \\left \\{\\,\\,\\left(p,j\\right)\\,\\,\\rvert \\,\\,x_{p,\\,j}  \\,\\,\\text{exists}  \\right \\}.\n",
    "\\end{equation}\n",
    "\n",
    "Stacking these user-rating vectors columnwise gives us our ratings matrix that we wish to complete\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \\begin{bmatrix} \n",
    "\\vert \\,\\,\\,\\,\\,\\, \\vert \\,\\,\\,\\,\\,...\\,\\,\\,\\,\\vert \\\\\n",
    "\\mathbf{x}_1 \\,\\, \\mathbf{x}_2 \\,\\,...\\,\\,\\mathbf{x}_P \\\\\n",
    "\\vert \\,\\,\\,\\,\\,\\, \\vert \\,\\,\\,\\,\\,...\\,\\,\\,\\,\\vert\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "In order to complete a sparsely populated ratings matrix effectively - because the data we are aiming to fill in is literally missing - we have no choice but to make assumptions about how users' tastes behave in general.   The most common / simplest assumption we can make - and the one we discuss here - is that every user's tastes can be expressed as a linear combination of some small set of fundamental user taste-profiles.  For example, in the case of movies these profiles could include the prototypical romance movie lover, prototypical comedy movie lover, action movie lover, etc.,  The relatively small number of such categories or user types compared to the total number of users or movies / products / etc., in a ratings matrix, provides a useful framework to intelligenty guess at the ratings matrix's missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this assumption help us complete the ratings matrix?  In order to find out we need to translate this intuitive assumption into mathematics.  When stated mathematically this assumption says that there are some set of $K < N$ prototypical user-rating profile basis vectors $\\mathbf{c}_1,\\,\\mathbf{c}_2,\\,..,\\,\\mathbf{c}_K$ so that we can express (approximately) every *complete* user-profile vector (given also the ideal weights in each linear combination) as \n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{n=1}^K \\mathbf{c}_n w_{p,n} \\approx \\mathbf{x}_p  \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, p=1...P\n",
    "\\end{equation}\n",
    "\n",
    "Again here we suppose that both the prototypical rating profile vectors $\\mathbf{c}_1,\\,...\\,\\mathbf{c}_K$ and the weights $w_{p,n}$ are ideal.  In practice we need to learn the proper values of these parameters, and from here we could then propose to square the difference of each desired approximation above and sum the result (which would give precisely the Least Squares cost function for PCA we derived in Section 9.2.1 and also 9.2.5).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However before doing this here we need to be careful - remember we only have access to entries of the ratings matrix whose indices lie in the set $\\Omega$.  On the other hand, the ideal approximation above gives us an estimate for *every* entry of the matrix.  Before forming a Least Squares cost function whose minimizer corresponds to properly tuned parameters here we need to restrict the ideal approximations above to the set of data we actually have (those entries in our index set $\\Omega$).  We can write this set of actual equalities somewhat abstractly by using the notation $\\approx_{\\Omega}$ to denote an approximation only for indices in the set $\\Omega$ giving the similar looking formula\n",
    "\n",
    "\\begin{equation}\n",
    "\\sum_{n=1}^K \\mathbf{c}_n w_{p,n} \\approx_{\\Omega} \\mathbf{x}_p    \\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\, p=1...P.\n",
    "\\end{equation}\n",
    "\n",
    "In other words, we only care about the approximation holding for indecies in the set $\\Omega$ (since these are the only non-empty entries of $\\mathbf{X}$ / ratings entries we have)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLAH  average over all $P$ points gives a Least Squares cost function for learning recommendations that closely mirrors the one or PCA as\n",
    "\n",
    "\\begin{equation}\n",
    "g\\left(\\mathbf{w}_1,...,\\mathbf{w}_p,\\mathbf{c}_1,...,\\mathbf{c}_K\\right) = \\frac{1}{P}\\sum_{p=1}^P \\left.\\left(\\sum_{n=1}^K \\mathbf{c}_n w_{p,n} - \\mathbf{x}_p   \\right)^2\\right\\vert_{\\Omega}.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is indeed so similar to the cost function for PCA it should be inticing - at least at first - to wonder whether or not we can divine a straight-forward minimizer if we assume additionally that the set of $K$ spoanning vectors is *orthonormal* (since we found that enforcing this constraint similarly produced a stunningly simple solution to PCA).  Unfortunately the fact that "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.4.3  Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *block-coordinate descent* approach is a very natural approach to minimizing this cost function (much as it is with the analgous PCA cost discussed in Section 9.2.1 and 9.2.5).  By cycling through each vector of parameters $\\mathbf{w}_1,...,\\mathbf{w}_P,\\mathbf{c}^{1},...,\\mathbf{c}^{\\,n}$ we can easily solve the first order system in each independently (keeping all of the others fixed), and hence sequentially minimize the cost function.  One can easily check that first order system of the cost function above in $\\mathbf{w}_p$ alone (keeping all other variables fixed) is \n",
    "\n",
    "\\begin{equation}\n",
    "\\left(\\sum_{(\\cdot,\\,j)\\in \\Omega}\\mathbf{c}^{\\,j}\\left(\\mathbf{c}^{\\,j}\\right)^T\\right)\\,\\mathbf{w}_p = \\sum_{(\\cdot,\\,j)\\in \\Omega}x_{p,\\,j}\\left(\\mathbf{c}^{\\,j}\\right)^T.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an $N\\times N$ linear and symmetric system of equations that is easily solvable (via e.g., coordinate descent in each individual entry of $\\mathbf{w}_p$), whose solution gives the updated version of $\\mathbf{w}_p$.  \n",
    "\n",
    "The analgous first order system for $\\mathbf{c}^{\\,j}$ can likewise be computed as \n",
    "\n",
    "\\begin{equation}\n",
    "\\left(\\sum_{(p,\\cdot)\\in \\Omega}\\mathbf{w}_p^{\\,}\\mathbf{w}_p^{T}\\right) \\left(\\mathbf{c}^{\\,j}\\right)^T =  \\sum_{(p,\\,\\cdot)\\in \\Omega}x_{p,\\,j}\\mathbf{w}_p.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a $K\\times K$ linear and symmetric system of equations that is easily solvable (via e.g., coordinate descent in each individual entry of $\\mathbf{c}^{\\,j}$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sweeping through the parameter vectors and performing these updates a number of times results in a proper solution to the Least Squares cost function detailed above.  Below we collect these update steps in a pseudo-code block for convenience.  Comparing this procedure to the block-coordinate descent algorithm described in Section 9.2.1, notice that if $\\Omega = \\emptyset$, that is if we have every rating, then we are performing PCA here.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommender systems  (block-coordinate descent) \n",
    "\n",
    "<hr style=\"height:1px;border:none;color:#555;background-color:#555;\">\n",
    "<p style=\"line-height: 1.7;\">\n",
    "<strong>1:</strong>&nbsp;&nbsp; <strong>input:</strong> a number $K \\leq N$ of desired principal components, dataset $\\mathbf{x}_1,...,\\mathbf{x}_P$, initializations for basis $\\mathbf{c}_1,...,\\mathbf{c}_K$, and maximum number of iterations $\\text{max_its}$ <br>\n",
    "\n",
    "<strong>2:</strong>&nbsp;&nbsp; <code>compute</code> mean of dataset $\\boldsymbol{\\mu} = \\frac{1}{P}\\sum_{p=1}^P\\mathbf{x}_p$ and center data as $\\mathbf{x}_p \\longleftarrow \\mathbf{x}_p - \\boldsymbol{\\mu}$ for $p=1,...,P$ <br> \n",
    "\n",
    "<strong>3:</strong>&nbsp;&nbsp; <code>for</code> $\\,\\,i = 1,\\ldots,\\text{max_its}$<br>\n",
    "\n",
    "<strong>4:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code># Update weight vectors</code><br>\n",
    "\n",
    "<strong>5:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code>for</code> $\\,\\,p = 1,\\ldots,P$<br>\n",
    "\n",
    "<strong>6:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code> solve </code> $\\mathbf{C}^T\\mathbf{C}^{\\,}\\mathbf{w}_p = \\mathbf{C}^T\\mathbf{x}_p$ for $\\mathbf{w}_p$ <br>\n",
    "\n",
    "<strong>7:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code>end for</code><br>\n",
    "\n",
    "<strong>8:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code># Update basis</code><br>\n",
    "\n",
    "<strong>9:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code>for</code> $\\,\\,n = 1,\\ldots,K$<br>\n",
    "\n",
    "<strong>10:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code> solve </code> $\\mathbf{c}_n = \\frac{\\sum_{p=1}^P \\mathbf{x}_p w_{p,n} } {\\sum_{p=1}^P w_{p,n}^2}$<br>\n",
    "\n",
    "<strong>11:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code>end for</code><br>\n",
    "\n",
    "<strong>12:</strong>&nbsp; <code>end for</code><br>\n",
    "\n",
    "<strong>13:</strong>&nbsp;&nbsp; <code># Update weights on final basis</code><br>\n",
    "\n",
    "\n",
    "<strong>14:</strong>&nbsp;&nbsp;&nbsp; <code>for</code> $\\,\\,p = 1,\\ldots,P$<br>\n",
    "\n",
    "<strong>15:</strong>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <code> solve </code> $\\mathbf{C}^T\\mathbf{C}^{\\,}\\mathbf{w}_p = \\mathbf{C}^T\\mathbf{x}_p$ for $\\mathbf{w}_p$ <br>\n",
    "\n",
    "<strong>16:</strong>&nbsp;&nbsp; <code>end for</code><br>\n",
    "\n",
    "<strong>17:</strong>&nbsp; <strong>output:</strong> optimal PCA basis $\\mathbf{c}_1,...,\\mathbf{c}_K$ and weights $\\mathbf{w}_1,...,\\mathbf{w}_P$<br>\n",
    "\n",
    "<hr style=\"height:1px;border:none;color:#555;background-color:#555;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 1: </span>  A simple example learning a spanning set via Principal Component Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(X,C):\n",
    "    # Update weight vectors\n",
    "    P,N = X.shape\n",
    "    W = []\n",
    "    \n",
    "    # pre-compute elements of each linear system\n",
    "    CTC = np.dot(C.T,C)\n",
    "    for p in range(N):\n",
    "        # setup linear system\n",
    "        w_p = np.array(np.linalg.solve(CTC,np.dot(C.T,X[:,p][:,np.newaxis]))).ravel()\n",
    "        W.append(w_p)\n",
    "        \n",
    "    # return weight matrix\n",
    "    W = np.array(W).T\n",
    "    return W\n",
    "\n",
    "def update_basis(X,W):\n",
    "    # Update basis vectors \n",
    "    K,P = W.shape\n",
    "    C = []\n",
    "    for n in range(K):\n",
    "        # update nth element of basis\n",
    "        c_n = np.sum(X*W[n,:][np.newaxis,:],axis = 1)/(np.sum(W[n,:]*W[n,:]))\n",
    "        C.append(c_n)\n",
    "        \n",
    "    # return updated basis\n",
    "    C = np.array(C).T\n",
    "    return C\n",
    "\n",
    "def block_coord_PCA(X,C,max_its):\n",
    "    # Outer loop - over iterations\n",
    "    for i in range(max_its):\n",
    "        # update weights\n",
    "        W = update_weights(X,C)\n",
    "\n",
    "        # update basis\n",
    "        C = update_basis(X,W)\n",
    "        \n",
    "    # final weight update\n",
    "    W = update_weights(X,C)\n",
    "    \n",
    "    # return PCs and weights\n",
    "    return C,W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_basis(X,W):\n",
    "    # Update basis vectors \n",
    "    K,P = W.shape\n",
    "    C = []\n",
    "    for j in range(K):\n",
    "        # setup linear system\n",
    "        ind = np.isnan(X[j,:])\n",
    "        om = np.argwhere(ind == True)\n",
    "        A = np.dot(W[:,om],W[:,om].T)\n",
    "        b =  np.sum(X[p,om]*X[:,om])\n",
    "\n",
    "        # solve linear system and store\n",
    "        c_j = np.linalg.lstsq(A,b).T \n",
    "        C.append(c_j)\n",
    "        \n",
    "    # return updated basis\n",
    "    return C\n",
    "\n",
    "def recommender_system(X,C,max_its):\n",
    "    # Outer loop - over iterations\n",
    "    for i in range(max_iters):\n",
    "        # update weights\n",
    "        W = update_weights(X,C)\n",
    "        \n",
    "        # update basis\n",
    "        C = update_basis(X,W)\n",
    "        \n",
    "    # final weight update\n",
    "    W = update_weights(X,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test matrix ###\n",
    "# generate full ratings matrix\n",
    "N = 10; K = 4;\n",
    "X_orig = np.round(5*np.random.rand(N,N))\n",
    "X = copy.deepcopy(X_orig)\n",
    "\n",
    "# remove percentage of entries\n",
    "removal_percentage = 0.5\n",
    "removal_portion = round(removal_percentage*np.size(X_orig))\n",
    "indices = np.random.permutation(np.size(X_orig))[:removal_portion]\n",
    "X.ravel()[indices] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate initialization for basis\n",
    "C = np.random.randn(N,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(X,C):\n",
    "    # Update weight vectors\n",
    "    N,P = X.shape\n",
    "    W = []\n",
    "    for p in range(P):\n",
    "        # setup linear system\n",
    "        ind = np.isnan(X[:,p])\n",
    "        om = np.argwhere(ind == True).ravel()\n",
    "        A = np.dot(C[om,:],C[om,:].T)\n",
    "    \n",
    "        \n",
    "        b =  np.dot(X[om,p][np.newaxis,:],C[om,:])\n",
    "\n",
    "        # solve linear system and store weights\n",
    "#         print (np.shape(A))\n",
    "#         print (np.shape(b))\n",
    "        w_p = np.linalg.lstsq(A,b)\n",
    "        W.append(w_p)\n",
    "    \n",
    "    # return weight matrix\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4, 4)\n",
      "(1, 4)\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "Incompatible dimensions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1a669bc346af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-6e7cd3dc6213>\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(X, C)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#         print (np.shape(A))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#         print (np.shape(b))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mw_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   1924\u001b[0m     \u001b[0mldb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1926\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Incompatible dimensions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1927\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m     \u001b[0mresult_real_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Incompatible dimensions"
     ]
    }
   ],
   "source": [
    "W = update_weights(X,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## This code cell will not be shown in the HTML version of this notebook\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "\n",
    "# demos for this notebook\n",
    "regress_plotter = superlearn.lin_regression_demos\n",
    "optimizers = optlib.optimizers\n",
    "static_plotter = optlib.static_plotter.Visualizer()\n",
    "datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "# import autograd functionality to bulid function's properly for optimizers\n",
    "import autograd.numpy as np\n",
    "\n",
    "# import timer\n",
    "from datetime import datetime \n",
    "\n",
    "# this is needed to compensate for %matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two issues here\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\omega = \\left[b,\\mathbf{w}\\right]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How autograd guys do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(params, inputs):\n",
    "    for W, b in params\n",
    "        outputs = np.dot(inputs, W) + b\n",
    "        inputs = np.tanh(outputs) \n",
    "    return outputs\n",
    "\n",
    "def loss(params, inputs, targets): \n",
    "    preds = predict(params, inputs) \n",
    "    return np.sum((preds - targets)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\code{blah}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and likewise our Least Squares cost function itself as\n",
    "\n",
    "\\begin{equation}\n",
    "\\,g\\left(\\theta\\right)=\\frac{1}{P}\\sum_{p=1}^{P}\\left(\\text{model}\\left(\\mathbf{x}_{p},\\theta\\right)  -y_{p}^{\\,}\\right)^{2}.\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "\n",
    "\\begin{equation}\n",
    "\\theta = \\left\\{b,\\mathbf{w} \\right\\}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.3  Implementing the Least Squares cost in `Python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\text{model}\\left(\\mathbf{x}_{p},\\left\\{b,\\mathbf{w}\\right\\}\\right) = b + \\mathbf{x}_{p}^T \\mathbf{w}.\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{model}\\left(\\mathbf{x}_{p},\\mathbf{w}\\right)   \\approx y_p\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "g\\left(b,\\mathbf{w}\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "g\\left(\\omega\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute linear combination of input point\n",
    "def model(x_p,w):\n",
    "    # compute linear combination and return\n",
    "    a = w[0] + np.dot(x_p.T,w[1:])\n",
    "    return a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a least squares function for linear regression\n",
    "def least_squares(w,x,y):    \n",
    "    # loop over points and compute cost contribution from each input/output pair\n",
    "    cost = 0\n",
    "    for p in range(y.size):\n",
    "        # get pth input/output pair\n",
    "        x_p = x[:,p][:,np.newaxis]\n",
    "        y_p = y[p]\n",
    "\n",
    "        ## add to current cost\n",
    "        cost += (model(x_p,w)  - y_p)**2\n",
    "        \n",
    "    # return average least squares error\n",
    "    return cost/float(y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute linear combination of input points\n",
    "def model(x,w):\n",
    "    a = w[0] + np.dot(x.T,w[1:])\n",
    "    return a.T\n",
    "\n",
    "# an implementation of the least squares cost function for linear regression\n",
    "def least_squares(w):    \n",
    "    # compute the least squares cost\n",
    "    cost = np.sum((model(x,w) - y)**2)\n",
    "    return cost/float(y.size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

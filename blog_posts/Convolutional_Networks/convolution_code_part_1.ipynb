{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autograd import grad as compute_grad   \n",
    "import autograd.numpy as np\n",
    "import numpy as npo\n",
    "import copy\n",
    "from datetime import datetime \n",
    "\n",
    "#this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: convolution code - naive version and effecient tensor-based version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The most naive convolution code ever (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a stack of feature maps of an input tensor of images we first try the most naive approach ever - we construct one feature map at a time by looping through all images, and for each image constructing a feature map for each convolution kernel (again by explicitly looping through the kernels).  \n",
    "\n",
    "There is nothing mathematically wrong with taking the naive way out - all of the computations here will be correct, and we can use this as either a fixed convolution feature extractor or place it in a feedforward network and learn the kernels.  Computationally speaking, however, this will be extremely slow in ``Python`` due to all of the nexted for-loops!  We will re-write this exact computation below using ``tensors`` instead of individual images / kernels, which will drastically improve computation speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naive_conv_layer:\n",
    "    '''\n",
    "    A simple convnet module.  Here we calculate feature maps exactly one at a time, using\n",
    "    a host of nested for-loops.  This means computation will be quite slow!  However this\n",
    "    can still be used in theory as a fixed convolutional feature extractor or as a convolutional\n",
    "    layer in a conv net (where the kernels are learned).\n",
    "    '''   \n",
    "    \n",
    "    # a convolution function\n",
    "    def conv_function(self,window):\n",
    "        conv = np.sum(self.kernel*window)\n",
    "        return conv\n",
    "\n",
    "    # a pooling function\n",
    "    def pool_function(self,window):\n",
    "        pool = np.max(window)\n",
    "        return pool\n",
    "\n",
    "    # activation function\n",
    "    def activation(self,window):\n",
    "        a = np.maximum(0,window)\n",
    "        return a\n",
    "    \n",
    "    # pad image with appropriate number of zeros for convolution\n",
    "    def pad_image(self,image,kernel_size):\n",
    "        odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "        pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "        image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "        image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "        return image_padded          \n",
    "    \n",
    "    # sliding window function, convolution or pooling done on each window\n",
    "    def sliding_window_image(self,image,window_size,stride,func):\n",
    "        # grab image size, set container for results\n",
    "        image_size = np.shape(image)[0]\n",
    "        results = []\n",
    "\n",
    "        # slide window over input image with given window size / stride and function\n",
    "        for i in np.arange(0, image_size - window_size + 1, stride):\n",
    "            for j in np.arange(0, image_size - window_size + 1, stride):\n",
    "                # now we have a window from our image, and use the desired 'func' to process it\n",
    "                window = image[i:i+window_size,j:j+window_size]\n",
    "\n",
    "                # process using input func\n",
    "                processed_window = func(window)\n",
    "                results.append(processed_window)\n",
    "\n",
    "        # array-afy results\n",
    "        results = np.array(results)\n",
    "\n",
    "        # return results in numpy array format\n",
    "        return results\n",
    "    \n",
    "    # make feature map for input inage and kernel\n",
    "    def make_feature_map(self,image,kernel):\n",
    "        # parameters for transform\n",
    "        kernel_size = kernels[0].shape[0]\n",
    "        pool_kernel_size = 6\n",
    "        stride = 3\n",
    "    \n",
    "        # pad image with zeros\n",
    "        padded_image = self.pad_image(image,kernel_size)\n",
    "        \n",
    "        # window image\n",
    "        feature_map = self.sliding_window_image(padded_image,kernel_size,stride = 1,func = self.conv_function)\n",
    "        \n",
    "        # reshape convolution feature map into array\n",
    "        feature_map = np.reshape(feature_map,(np.shape(image)))\n",
    "        \n",
    "        # now shove result through nonlinear activation\n",
    "        feature_map = self.activation(feature_map)\n",
    "\n",
    "        #### now pool / downsample feature map, first window then pool on each window\n",
    "        max_pool = self.sliding_window_image(feature_map,pool_kernel_size,stride = stride,func = self.pool_function)\n",
    "\n",
    "        # reshape into new tensor\n",
    "        max_pool = np.reshape(max_pool, (int((np.size(max_pool))**(0.5)),int((np.size(max_pool))**(0.5))))\n",
    "\n",
    "        return max_pool\n",
    "        \n",
    "    # main convolution layer definition\n",
    "    def conv_layer(self,images,kernels):\n",
    "        #### create image tensor from input images\n",
    "        image_tensor = np.reshape(images,(np.shape(images)[0],int((np.shape(images)[1])**(0.5)),int( (np.shape(images)[1])**(0.5))),order = 'F')\n",
    "\n",
    "        #### loop over each image, shove through filters and make feature maps, then downsample and pool\n",
    "        new_tensors = []\n",
    "\n",
    "        #### loop over images\n",
    "        for image in image_tensor:\n",
    "            #### loop over kernels and construct feature map for each kernel\n",
    "            downsampled_feature_maps = []\n",
    "            for kernel in kernels:\n",
    "                self.kernel = kernel\n",
    "                downsampled_map = self.make_feature_map(image,kernel)\n",
    "                downsampled_feature_maps.append(downsampled_map)\n",
    "            \n",
    "            ## re-shape downsampled_feature_maps and store\n",
    "            new_tensors.append(downsampled_feature_maps)\n",
    "\n",
    "        # reshape new tensor properly\n",
    "        new_tensors = np.array(new_tensors)\n",
    "        new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "        new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "        return new_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A much more effecient tensor-based implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By carefully thinking about how convolutional feature maps are constructed on a set of images we can re-write the implementation above in a much more effecient manner by employing ``tensors`` - i.e., three (and higher) dimensional matrices.  Here the entire stack (``tensor``) of images is processed simultaneously, minimizing the number of explicit for-loops required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tensor_conv_layer:    \n",
    "    # convolution function\n",
    "    def conv_function(self,tensor_window):\n",
    "        tensor_window = np.reshape(tensor_window,(np.shape(tensor_window)[0],np.shape(tensor_window)[1]*np.shape(tensor_window)[2]))\n",
    "        t = np.dot(self.kernels,tensor_window.T)\n",
    "        return t\n",
    "\n",
    "    # pooling / downsampling parameters\n",
    "    def pool_function(self,tensor_window):\n",
    "        t = np.max(tensor_window,axis = (1,2))\n",
    "        return t\n",
    "\n",
    "    # activation \n",
    "    def activation(self,tensor_window):\n",
    "        return np.maximum(0,tensor_window)\n",
    "\n",
    "    # pad image with appropriate number of zeros for convolution\n",
    "    def pad_tensor(self,tensor,kernel_size):\n",
    "        odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "        pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "        tensor_padded = np.zeros((np.shape(tensor)[0], np.shape(tensor)[1] + 2*pad_val,np.shape(tensor)[2] + 2*pad_val))\n",
    "        tensor_padded[:,pad_val:-pad_val,pad_val:-pad_val] = tensor\n",
    "        return tensor_padded    \n",
    "    \n",
    "    # sliding window for image augmentation\n",
    "    def sliding_window_tensor(self,tensor,window_size,stride,func):\n",
    "        # grab image size, set container for results\n",
    "        image_size = np.shape(tensor)[1]\n",
    "        results = []\n",
    "        \n",
    "        # slide window over input image with given window size / stride and function\n",
    "        for i in np.arange(0, image_size - window_size + 1, stride):\n",
    "            for j in np.arange(0, image_size - window_size + 1, stride):\n",
    "                # take a window of input tensor\n",
    "                tensor_window =  tensor[:,i:i+window_size, j:j+window_size]\n",
    "                \n",
    "                # now process entire windowed tensor at once\n",
    "                tensor_window = np.array(tensor_window)\n",
    "                yo = func(tensor_window)\n",
    "\n",
    "                # store weight\n",
    "                results.append(yo)\n",
    "        \n",
    "        # re-shape properly\n",
    "        results = np.array(results)\n",
    "        results = results.swapaxes(0,1)\n",
    "        if func == self.conv_function:\n",
    "            results = results.swapaxes(1,2)\n",
    "        return results \n",
    "\n",
    "    # make feature map\n",
    "    def make_feature_tensor(self,tensor):\n",
    "        # create feature map via convolution --> returns flattened convolution calculations\n",
    "        conv_stride = 1\n",
    "        feature_tensor = self.sliding_window_tensor(tensor,self.kernel_size,conv_stride,self.conv_function) \n",
    "\n",
    "        # re-shape convolution output ---> to square of same size as original input\n",
    "        num_filters = np.shape(feature_tensor)[0]\n",
    "        num_images = np.shape(feature_tensor)[1]\n",
    "        square_dim = int((np.shape(feature_tensor)[2])**(0.5))\n",
    "        feature_tensor = np.reshape(feature_tensor,(num_filters,num_images,square_dim,square_dim))\n",
    "        \n",
    "        # shove feature map through nonlinearity\n",
    "        feature_tensor = self.activation(feature_tensor)\n",
    "\n",
    "        # pool feature map --- i.e., downsample it\n",
    "        pool_stride = 3\n",
    "        pool_window_size = 6\n",
    "        downsampled_feature_map = []\n",
    "        for t in range(np.shape(feature_tensor)[0]):\n",
    "            temp_tens = feature_tensor[t,:,:,:]\n",
    "            d = self.sliding_window_tensor(temp_tens,pool_window_size,pool_stride,self.pool_function)\n",
    "            downsampled_feature_map.append(d)\n",
    "        downsampled_feature_map = np.array(downsampled_feature_map)\n",
    "\n",
    "        # return downsampled feature map --> flattened\n",
    "        return downsampled_feature_map\n",
    "\n",
    "    # our normalization function\n",
    "    def normalize(self,data,data_mean,data_std):\n",
    "        normalized_data = (data - data_mean)/(data_std + 10**(-5))\n",
    "        return normalized_data\n",
    "\n",
    "    # convolution layer\n",
    "    def conv_layer(self,tensor,kernels):\n",
    "        #### prep input tensor #####\n",
    "        # pluck out dimensions for image-tensor reshape\n",
    "        num_images = np.shape(tensor)[0]\n",
    "        num_kernels = np.shape(kernels)[0]\n",
    "        \n",
    "        # create tensor out of input images (assumed to be stacked vertically as columns)\n",
    "        tensor = np.reshape(tensor,(np.shape(tensor)[0],int((np.shape(tensor)[1])**(0.5)),int( (np.shape(tensor)[1])**(0.5))),order = 'F')\n",
    "\n",
    "        # pad tensor\n",
    "        kernel = kernels[0]\n",
    "        self.kernel_size = np.shape(kernel)[0]\n",
    "        padded_tensor = self.pad_tensor(tensor,self.kernel_size)\n",
    "\n",
    "        #### prep kernels - reshape into array for more effecient computation ####\n",
    "        self.kernels = np.reshape(kernels,(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]))\n",
    "        \n",
    "        #### compute convolution feature maps / downsample via pooling one map at a time over entire tensor #####\n",
    "        # compute feature map for current image using current convolution kernel\n",
    "        feature_tensor = self.make_feature_tensor(padded_tensor)\n",
    "\n",
    "        feature_tensor = feature_tensor.swapaxes(0,1)\n",
    "        feature_tensor = np.reshape(feature_tensor, (np.shape(feature_tensor)[0],np.shape(feature_tensor)[1]*np.shape(feature_tensor)[2]),order = 'F')\n",
    "        \n",
    "        return feature_tensor\n",
    "    \n",
    "    ##### some supervised learning capabilities #####\n",
    "    def load_data(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def predict(self,x,w):\n",
    "        # pass input data through convolutional layer\n",
    "        x_conv = self.conv_layer(x,w[0])\n",
    "        \n",
    "        # take inner product against output of conv layer\n",
    "        value = w[1][0] + np.dot(x_conv,w[1][1:])\n",
    "        return value\n",
    "    \n",
    "    # the softmax cost function \n",
    "    def softmax(self,w):\n",
    "        cost  = np.sum(np.log(1 + np.exp((-self.y)*(self.predict(self.x,w)))))\n",
    "        return cost\n",
    "    \n",
    "    def count(self,w):\n",
    "        return 0.25*np.sum((np.sign(self.predict(self.x,w)) - self.y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A speed test in evaluating the convolution layers implemented above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets compare the speeds of our naive versus tensor-based convolution layer implementations using the face detection image dataset and the set of edge detecting kernels given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "edge_detection_kernels = np.array([\n",
    "       [[-1, -1, -1],\n",
    "        [ 0,  0,  0],\n",
    "        [ 1,  1,  1]],\n",
    "\n",
    "       [[-1, -1,  0],\n",
    "        [-1,  0,  1],\n",
    "        [ 0,  1,  1]],\n",
    "    \n",
    "        [[-1,  0,  1],\n",
    "        [-1,  0,  1],\n",
    "        [-1,  0,  1]],\n",
    "\n",
    "       [[ 0,  1,  1],\n",
    "        [-1,  0,  1],\n",
    "        [-1, -1,  0]],\n",
    "\n",
    "       [[ 1,  0, -1],\n",
    "        [ 1,  0, -1],\n",
    "        [ 1,  0, -1]],\n",
    "\n",
    "       [[ 0, -1, -1],\n",
    "        [ 1,  0, -1],\n",
    "        [ 1,  1,  0]],\n",
    "\n",
    "       [[ 1,  1,  1],\n",
    "        [ 0,  0,  0],\n",
    "        [-1, -1, -1]],\n",
    "\n",
    "       [[ 1,  1,  0],\n",
    "        [ 1,  0, -1],\n",
    "        [ 0, -1, -1]]])          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try it out.  Here we will use the ``datetime`` library to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare instances of each convolution function\n",
    "naive_conv_test = naive_conv_layer()\n",
    "tensor_conv_test = tensor_conv_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernels = np.random.randn(1,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the face detection dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "datapath = '../../mlrefined_datasets/convnet_datasets/feat_face_data.csv'\n",
    "data = np.loadtxt(datapath,delimiter = ',')\n",
    "\n",
    "# import data and reshape appropriately\n",
    "x = data[:,:-1]\n",
    "y = data[:,-1:1]\n",
    "\n",
    "# take a small number of examples for the speed test\n",
    "x = x[:1000,:]\n",
    "y = y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a set of fixed convolution features (using edge detecting kernels) - first using our naive implementation ``naive_conv_layer``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:01:37.267523\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "feature_maps_1 = naive_conv_test.conv_layer(x,edge_detection_kernels)\n",
    "\n",
    "# finish timing\n",
    "timeElapsed=datetime.now()-startTime \n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our more effecient tensor-based implementation ``tensor_conv_layer``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.348938\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "feature_maps_2 = tensor_conv_test.conv_layer(x,edge_detection_kernels)\n",
    "\n",
    "# finish timing\n",
    "timeElapsed=datetime.now()-startTime \n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow!  Thats around 1000 times faster.  Compare numerically each computation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8357429832731845e-15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_maps_1-feature_maps_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

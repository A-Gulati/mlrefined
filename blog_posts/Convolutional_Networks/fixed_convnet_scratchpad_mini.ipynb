{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal as sig\n",
    "\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "from mlrefined_libraries import convnets_library as convlib\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import multilayer_perceptron_library as network_lib\n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import grad as compute_grad   \n",
    "\n",
    "import autograd.numpy as np\n",
    "import numpy as npo\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import csv\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime \n",
    "\n",
    "#this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fixed convolution feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in test bank of kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy over test kernels\n",
    "new_kernels = []\n",
    "kernels = convlib.image_viz.load_kernels()\n",
    "for ind, kernel in kernels.items():\n",
    "    new_kernels.append(kernel)\n",
    "new_kernels = np.asarray(new_kernels)\n",
    "kernels = copy.deepcopy(new_kernels)\n",
    "kernels = kernels[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "demo = network_lib.network_learner.Network()\n",
    "\n",
    "# load in dataset\n",
    "datapath = '../../mlrefined_datasets/convnet_datasets/feat_face_data.csv'\n",
    "data = np.loadtxt(datapath,delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed conv transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sliding window for image augmentation\n",
    "def sliding_window_tensor(tensor, kernel, stride):\n",
    "    windowed_tensor = []\n",
    "    for i in np.arange(0, np.shape(tensor)[1]-kernel.shape[0]+1, stride):\n",
    "        for j in np.arange(0, np.shape(tensor)[2]-kernel.shape[1]+1, stride):\n",
    "            sock = copy.deepcopy(tensor[:,i:i+kernel.shape[0], j:j+kernel.shape[1]])\n",
    "            windowed_tensor.append(sock)\n",
    "    \n",
    "    # re-shape properly\n",
    "    windowed_tensor = np.array(windowed_tensor)\n",
    "    windowed_tensor = windowed_tensor.swapaxes(0,1)    \n",
    "    windowed_tensor = np.reshape(windowed_tensor,(np.shape(windowed_tensor)[0]*np.shape(windowed_tensor)[1],np.shape(windowed_tensor)[2]*np.shape(windowed_tensor)[3]))   \n",
    "    return windowed_tensor\n",
    "\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_tensor(tensor,kernel):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    val = kernel.shape[0]\n",
    "    pad_val = np.argwhere(odd_nums == val)[0][0]\n",
    "    tensor_padded = np.zeros((np.shape(tensor)[0], np.shape(tensor)[1] + 2*pad_val,np.shape(tensor)[2] + 2*pad_val))\n",
    "    tensor_padded[:,pad_val:-pad_val,pad_val:-pad_val] = tensor\n",
    "    return tensor_padded    \n",
    "\n",
    "# activation \n",
    "def activation(t):\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "# our normalization function\n",
    "def normalize(data,data_mean,data_std):\n",
    "    normalized_data = (data - data_mean)/(data_std + 10**(-5))\n",
    "    return normalized_data\n",
    "\n",
    "def conv_layer(tensor,kernels):\n",
    "    # square up tensor into tensor of patches\n",
    "    tensor = np.reshape(tensor,(np.shape(tensor)[0],int((np.shape(tensor)[1])**(0.5)),int( (np.shape(tensor)[1])**(0.5))),order = 'F')\n",
    "    \n",
    "    # pad tensor\n",
    "    kernel = kernels[0]\n",
    "    padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "    # window tensor\n",
    "    wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "    # normalize windows since they touch weights\n",
    "    a_means = np.mean(wind_tensor,axis = 0)\n",
    "    a_stds = np.std(wind_tensor,axis = 0)\n",
    "    wind_tensor = normalize(wind_tensor,a_means,a_stds)\n",
    "    \n",
    "    #### compute convolution feature maps / downsample via pooling one map at a time over entire tensor #####\n",
    "    kernel2 = np.ones((6,6))\n",
    "    stride = 3\n",
    "    new_tensors = []\n",
    "    for kernel in kernels:\n",
    "        #### make convolution feature map - via matrix multiplication over windowed tensor \n",
    "        feature_map = np.dot(wind_tensor,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "        # reshape convolution feature map into array\n",
    "        feature_map = np.reshape(feature_map,np.shape(tensor))\n",
    "\n",
    "        # now shove result through nonlinear activation\n",
    "        feature_map = activation(feature_map)\n",
    "\n",
    "        #### now pool / downsample feature map, first window then pool on each window\n",
    "        wind_featmap = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "\n",
    "        # max pool on each collected patch\n",
    "        max_pool = np.max(wind_featmap,axis = 1)\n",
    "            \n",
    "        # reshape into new tensor\n",
    "        max_pool = np.reshape(max_pool,(np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5))))\n",
    "        \n",
    "        # reshape into new downsampled pooled feature map\n",
    "        new_tensors.append(max_pool)\n",
    "\n",
    "    # turn into array\n",
    "    new_tensors = np.array(new_tensors)\n",
    "\n",
    "    # reshape into final feature vector to touch fully connected layer(s), otherwise keep as is in terms of shape\n",
    "    new_tensors = new_tensors.swapaxes(0,1)\n",
    "    new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "    new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "    return new_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform all input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract input tensor\n",
    "tensor = data[:2,:-1]\n",
    "y = data[:,2]\n",
    "\n",
    "# run through conv layer with fixed kernels\n",
    "new_tensor = conv_layer(tensor,kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 784)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor_wha = copy.deepcopy(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_wha = tensor_wha.reshape(np.shape(tensor)[0],int((np.shape(tensor)[1])**(0.5)),int( (np.shape(tensor)[1])**(0.5)),order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28, 28)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_wha.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = np.reshape(tensor,(np.shape(tensor)[0],int((np.shape(tensor)[1])**(0.5)),int( (np.shape(tensor)[1])**(0.5))),order = 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(tensor - tensor_wha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

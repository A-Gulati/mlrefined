{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal as sig\n",
    "\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "from mlrefined_libraries import convnets_library as convlib\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import multilayer_perceptron_library as network_lib\n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import grad as compute_grad   \n",
    "\n",
    "import autograd.numpy as np\n",
    "import numpy as npo\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import csv\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime \n",
    "\n",
    "#this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "\n",
    "def ScipyConv(image, kernel):\n",
    "    \n",
    "    # flip kernel\n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "    \n",
    "    # compute convolution\n",
    "    conv = signal.convolve2d(image, kernel, boundary='fill', fillvalue=0, mode='same')\n",
    "    return conv  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenated image version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sliding window for image augmentation\n",
    "def sliding_window_image(image, kernel, stride):\n",
    "    windowed_image = []\n",
    "    for i in np.arange(0, np.shape(image)[0]-kernel.shape[0]+1, stride):\n",
    "        for j in np.arange(0, np.shape(image)[1]-kernel.shape[1]+1, stride):\n",
    "             windowed_image.append(image[i:i+kernel.shape[0], j:j+kernel.shape[1]].flatten())\n",
    "            \n",
    "    return np.array(windowed_image)\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_image(image,kernel_size):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    val = kernel_size[0]\n",
    "    pad_val = np.argwhere(odd_nums == val)[0][0]\n",
    "    image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "    image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "    return image_padded          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate test image and kernel\n",
    "image = np.random.randn(5,5)\n",
    "kernel = np.ones((3,3))\n",
    "kernel_size = kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad image\n",
    "padded_image = pad_image(image,kernel_size)\n",
    "\n",
    "# window image\n",
    "wind_img = sliding_window_image(padded_image,kernel,stride = 1)\n",
    "\n",
    "# produce matrix multiplication convolution \n",
    "conv2 = np.dot(wind_img,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "# reshape convolution into array\n",
    "conv2.shape = (np.shape(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(7, 7)\n",
      "(25, 9)\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(image))\n",
    "print(np.shape(padded_image))\n",
    "print(np.shape(wind_img))\n",
    "print(np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### baseline convolution #####\n",
    "conv1 = ScipyConv(image,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.59829705569e-15\n",
      "(5, 5) (5, 5)\n"
     ]
    }
   ],
   "source": [
    "#### compare convolutions ####\n",
    "error = np.linalg.norm(conv1 - conv2)\n",
    "print (error)\n",
    "print (np.shape(conv1),np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# activation \n",
    "def activation(t):\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "# output of activation\n",
    "a_conv = activation(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pool operation\n",
    "kernel2 = np.ones((2,2))\n",
    "wind_conv = sliding_window_image(a_conv,kernel2,stride = 2)\n",
    "\n",
    "# max pooling\n",
    "max_pool = np.max(wind_conv,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(wind_conv))\n",
    "print (np.shape(max_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# back to an image\n",
    "max_pool.shape = (int(np.size(max_pool)**(0.5)),int(np.size(max_pool)**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(max_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sliding window for image augmentation\n",
    "def sliding_window_tensor(tensor, kernel, stride):\n",
    "    windowed_tensor = []\n",
    "    for i in np.arange(0, np.shape(tensor)[1]-kernel.shape[0]+1, stride):\n",
    "        for j in np.arange(0, np.shape(tensor)[2]-kernel.shape[1]+1, stride):\n",
    "            sock = copy.deepcopy(tensor[:,i:i+kernel.shape[0], j:j+kernel.shape[1]])\n",
    "            windowed_tensor.append(sock)\n",
    "    \n",
    "    # re-shape properly\n",
    "    windowed_tensor = np.array(windowed_tensor)\n",
    "    windowed_tensor = windowed_tensor.swapaxes(0,1)    \n",
    "    windowed_tensor = np.reshape(windowed_tensor,(np.shape(windowed_tensor)[0]*np.shape(windowed_tensor)[1],np.shape(windowed_tensor)[2]*np.shape(windowed_tensor)[3]))   \n",
    "    return windowed_tensor\n",
    "\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_tensor(tensor,kernel):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    val = kernel.shape[0]\n",
    "    pad_val = np.argwhere(odd_nums == val)[0][0]\n",
    "    tensor_padded = np.zeros((np.shape(tensor)[0], np.shape(tensor)[1] + 2*pad_val,np.shape(tensor)[2] + 2*pad_val))\n",
    "    tensor_padded[:,pad_val:-pad_val,pad_val:-pad_val] = tensor\n",
    "    return tensor_padded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create test tensor\n",
    "tensor = np.random.randn(3,5,5)\n",
    "kernel = np.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad tensor\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "# # produce matrix multiplication convolution \n",
    "conv2 = np.dot(wind_tensor,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "# # reshape convolution into array\n",
    "conv2.shape = (np.shape(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 5)\n",
      "(3, 7, 7)\n",
      "(75, 9)\n",
      "(3, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(tensor))\n",
    "print(np.shape(padded_tensor))\n",
    "print(np.shape(wind_tensor))\n",
    "print(np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### baseline convolution #####\n",
    "convs = []\n",
    "for i in range(np.shape(tensor)[0]):\n",
    "    conv1 = ScipyConv(tensor[i,:,:],kernel)\n",
    "    convs.append(conv1)\n",
    "convs = np.asarray(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.70328477615e-15\n",
      "(3, 5, 5) (3, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "#### compare convolutions ####\n",
    "error = np.linalg.norm(convs - conv2)\n",
    "print (error)\n",
    "print (np.shape(convs),np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output of activation\n",
    "a_conv = activation(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pool operation\n",
    "kernel2 = np.ones((2,2))\n",
    "wind_conv = sliding_window_tensor(a_conv,kernel2,stride = 2)\n",
    "\n",
    "# max pooling\n",
    "max_pool = np.max(wind_conv,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(wind_conv))\n",
    "print (np.shape(max_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape into tensor\n",
    "max_pool.shape = (np.shape(tensor)[0],int(np.shape(wind_conv)[1]**(0.5)),int(np.shape(wind_conv)[1]**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(max_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with tensor and multiple kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create test tensor\n",
    "tensor = np.random.randn(3,28,28)\n",
    "kernels = np.random.randn(8,3,3)\n",
    "kernel = kernels[0]\n",
    "\n",
    "# pad tensor\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.011053\n"
     ]
    }
   ],
   "source": [
    "#### baseline convolution #####\n",
    "convs = []\n",
    "for kernel in kernels:\n",
    "    temp = []\n",
    "    for i in range(np.shape(tensor)[0]):\n",
    "        conv1 = ScipyConv(tensor[i,:,:],kernel)\n",
    "        temp.append(conv1)\n",
    "    temp = np.asarray(temp)\n",
    "    convs.append(temp)\n",
    "convs = np.asarray(convs)\n",
    "\n",
    "##### use tensor calculation from above ######\n",
    "\n",
    "startTime= datetime.now() \n",
    "\n",
    "conv2 = []\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "for kernel in kernels:\n",
    "    # # produce matrix multiplication convolution \n",
    "    conv = np.dot(wind_tensor,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "    # # reshape convolution into array\n",
    "    conv.shape = (np.shape(tensor))\n",
    "    conv = np.asarray(conv)\n",
    "    conv2.append(conv)\n",
    "conv2 = np.asarray(conv2)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.000470\n"
     ]
    }
   ],
   "source": [
    "# # SUPER COMPACT VERSION\n",
    "# # produce matrix multiplication convolution \n",
    "num_kernels = np.shape(kernels)[0]\n",
    "\n",
    "startTime= datetime.now() \n",
    "\n",
    "conv3 = np.dot(wind_tensor,kernels.reshape(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]).T).T\n",
    "\n",
    "# # reshape convolution into array\n",
    "a = np.shape(tensor)\n",
    "a = list(a)\n",
    "a.insert(0,num_kernels)\n",
    "a = tuple(a)\n",
    "conv3.shape = a\n",
    "\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.24989537868e-14\n",
      "(8, 3, 28, 28) (8, 3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#### compare convolutions  - either scipy or one kernel at a time ####\n",
    "error = np.linalg.norm(conv2 - convs)\n",
    "print (error)\n",
    "print (np.shape(convs),np.shape(conv3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of convolution we have `num_kernels` number of feature maps for our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to shove through activation and pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output of activation\n",
    "transformed_feature_maps = activation(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(transformed_feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pool operation\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for feature_map in transformed_feature_maps:\n",
    "    # move over feature map and gather patches\n",
    "    wind_conv = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "    \n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_conv,axis = 1)\n",
    "    \n",
    "    # reshape into new tensor\n",
    "    max_pool.shape = (np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)))\n",
    "    \n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "    \n",
    "# turn into array\n",
    "new_tensors = np.asarray(new_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 8, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step - as we feed into fully connected network component, make sure everything is reshaped correctly.  What the final output shape should be - one long vectorized sequence of 'feature maps' for each input image.  So here we are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    }
   ],
   "source": [
    "# reshape into final feature vector to touch fully connected layer(s)\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = new_tensors.reshape(np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]*np.shape(new_tensors)[3]).T\n",
    "print (np.shape(new_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    }
   ],
   "source": [
    "# create test tensor\n",
    "tensor = np.random.randn(3,28,28)\n",
    "kernels = np.random.randn(8,3,3)\n",
    "kernel = kernels[0]\n",
    "\n",
    "# pad tensor\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "#### create convolution feature maps ####\n",
    "feature_maps = np.dot(wind_tensor,kernels.reshape(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]).T).T\n",
    "\n",
    "# reshape feature maps back into arrays\n",
    "shapes = np.shape(tensor)\n",
    "shapes = list(shapes)\n",
    "shapes.insert(0,num_kernels)\n",
    "shapes = tuple(shapes)\n",
    "feature_maps.shape = shapes\n",
    "\n",
    "# push feature maps through activation\n",
    "transformed_feature_maps = activation(feature_maps)\n",
    "\n",
    "#### downsample via pooling ####\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for feature_map in transformed_feature_maps:\n",
    "    # move over feature map and gather patches\n",
    "    wind_conv = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "    \n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_conv,axis = 1)\n",
    "    \n",
    "    # reshape into new tensor\n",
    "    max_pool.shape = (np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)))\n",
    "    \n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "    \n",
    "# turn into array\n",
    "new_tensors = np.asarray(new_tensors)\n",
    "\n",
    "# reshape into final feature vector to touch fully connected layer(s)\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = new_tensors.reshape(np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]*np.shape(new_tensors)[3]).T\n",
    "print (np.shape(new_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test transformation on face images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data, transform via original method, transform via new method, compare features to make sure everything looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def load_data(datapath):\n",
    "    # load in data\n",
    "    data = np.loadtxt(datapath,delimiter = ',')\n",
    "\n",
    "    # import data and reshape appropriately\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    y.shape = (len(y),1)\n",
    "    \n",
    "    X_square = np.zeros((len(y),28,28))\n",
    "    for i in range(0,len(y)):\n",
    "        X_square[i,:,:] = np.reshape(X[i,:],(28,28),1)\n",
    "    \n",
    "    return X,X_square,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "datapath = '../../mlrefined_datasets/convnet_datasets/feat_face_data.csv'\n",
    "X,X_square, y = load_data(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_square = X_square[:10]\n",
    "X = X[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load kernels\n",
    "kernels = convlib.image_viz.load_kernels()\n",
    "\n",
    "# params\n",
    "sliding_window_size = (6,6) \n",
    "stride=3\n",
    "pooling_func= 'max'\n",
    "\n",
    "# get number of images in the dataset\n",
    "num_images = np.shape(X_square)[0]\n",
    "        \n",
    "# a test run to find the number of features with the params above\n",
    "test = convlib.image_viz.make_feat(X_square[0,:,:], kernels, sliding_window_size=sliding_window_size, stride=stride)\n",
    "num_features = np.shape(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.039566\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "# run old method\n",
    "feat = []\n",
    "for i in range(0,num_images):\n",
    "    # extract features\n",
    "    f = convlib.image_viz.make_feat(X_square[i,:,:], kernels, sliding_window_size=sliding_window_size,\n",
    "                                            stride=stride, pooling_func=pooling_func) \n",
    "    # store it\n",
    "    feat.append(f)\n",
    "    \n",
    "# convert to array\n",
    "feat = np.asarray(feat)\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New way - non-compact image version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-make original exposing all looping structures etc.,\n",
    "\n",
    "Far too slow - takes over a minute for just 4000 images - can't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy over test kernels\n",
    "new_kernels = []\n",
    "kernels = convlib.image_viz.load_kernels()\n",
    "for ind, kernel in kernels.items():\n",
    "    new_kernels.append(kernel)\n",
    "new_kernels = np.asarray(new_kernels)\n",
    "kernels = copy.deepcopy(new_kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign tensor name\n",
    "tensor = copy.deepcopy(X_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.570687\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime = datetime.now() \n",
    "\n",
    "# sliding window for image augmentation\n",
    "def sliding_window_image(image, kernel_size, stride):\n",
    "    windowed_image = []\n",
    "    for i in np.arange(0, np.shape(image)[0]-kernel_size+1, stride):\n",
    "        for j in np.arange(0, np.shape(image)[1]-kernel_size+1, stride):\n",
    "             windowed_image.append(image[i:i+kernel_size, j:j+kernel_size].flatten())\n",
    "            \n",
    "    return np.array(windowed_image)\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_image(image,kernel_size):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "    image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "    image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "    return image_padded          \n",
    "\n",
    "#### loop over each image, shove through filters and make feature maps, then downsample and pool\n",
    "new_tensors = []\n",
    "kernel_size = kernels[0].shape[0]\n",
    "pool_kernel_size = 6\n",
    "stride = 3\n",
    "\n",
    "#### loop over images\n",
    "for image in tensor:\n",
    "    # pad image with zeros\n",
    "    padded_image = pad_image(image,kernel_size)\n",
    "\n",
    "    #### loop over kernels and construct feature map for each kernel\n",
    "    downsampled_feature_maps = []\n",
    "    for kernel in kernels:\n",
    "        # window image\n",
    "        wind_img = sliding_window_image(padded_image,kernel_size,stride = 1)\n",
    "    \n",
    "        # make convolution feature map - via matrix multiplication over windowed tensor \n",
    "        feature_map = np.dot(wind_img,kernel.flatten()[:,np.newaxis])\n",
    "        \n",
    "        # reshape convolution feature map into array\n",
    "        feature_map = np.reshape(feature_map,(np.shape(image)))\n",
    "\n",
    "        # now shove result through nonlinear activation\n",
    "        feature_map = activation(feature_map)\n",
    "\n",
    "        #### now pool / downsample feature map, first window then pool on each window\n",
    "        wind_featmap = sliding_window_image(feature_map,pool_kernel_size,stride = stride)\n",
    "\n",
    "        # max pool on each collected patch\n",
    "        max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "        # reshape into new tensor\n",
    "        max_pool = np.reshape(max_pool, (int((np.size(max_pool))**(0.5)),int((np.size(max_pool))**(0.5))))\n",
    "\n",
    "        # reshape into new downsampled pooled feature map\n",
    "        downsampled_feature_maps.append(max_pool)\n",
    "        \n",
    "    ## re-shape downsampled_feature_maps and store\n",
    "    new_tensors.append(downsampled_feature_maps)\n",
    "\n",
    "# reshape new tensor properly\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6432407931151067e-16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_tensors - feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New way - non-compact tensor version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A somewhat effecient version of the feature transform code that is still somewhat understandable, about 4 times faster than most naive version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert kernel dictionary to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy over test kernels\n",
    "new_kernels = []\n",
    "kernels = convlib.image_viz.load_kernels()\n",
    "for ind, kernel in kernels.items():\n",
    "    new_kernels.append(kernel)\n",
    "new_kernels = np.asarray(new_kernels)\n",
    "kernels = copy.deepcopy(new_kernels)\n",
    "\n",
    "# assign tensor name\n",
    "tensor = X_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.021809\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "# activation \n",
    "def activation(t):\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "# square up bro\n",
    "tensor = np.reshape(X,(np.shape(X)[0],int((np.shape(X)[1])**(0.5)),int( (np.shape(X)[1])**(0.5))),order = 'F')\n",
    "\n",
    "        \n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "        \n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "#### compute convolution feature maps / downsample via pooling one map at a time over entire tensor #####\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for kernel in kernels:\n",
    "    #### make convolution feature map - via matrix multiplication over windowed tensor \n",
    "    feature_map = np.dot(wind_tensor,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "    # reshape convolution feature map into array\n",
    "    feature_map = np.reshape(feature_map,np.shape(tensor))\n",
    "\n",
    "    # now shove result through nonlinear activation\n",
    "    feature_map = activation(feature_map)\n",
    "\n",
    "    #### now pool / downsample feature map, first window then pool on each window\n",
    "    wind_featmap = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "\n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "    # reshape into new tensor\n",
    "    max_pool = np.reshape(max_pool,(np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5))))\n",
    "\n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "\n",
    "# turn into array\n",
    "new_tensors = np.array(new_tensors)\n",
    "\n",
    "# reshape into final feature vector to touch fully connected layer(s), otherwise keep as is in terms of shape\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6432407931151067e-16"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_tensors - feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New way - compact tensor version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More compact version - all kernel multiplications done at once - strangely is a bit slower than the one above, all the re-shaping must not be worth it, at least for this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.021039\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "# pad tensor\n",
    "kernel = kernels[0]\n",
    "num_kernels = np.shape(kernels)[0]\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "#### create convolution feature maps ####\n",
    "feature_maps = np.dot(wind_tensor,kernels.reshape(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]).T).T\n",
    "\n",
    "# reshape feature maps back into arrays\n",
    "shapes = np.shape(tensor)\n",
    "shapes = list(shapes)\n",
    "shapes.insert(0,num_kernels)\n",
    "shapes = tuple(shapes)\n",
    "feature_maps.shape = shapes\n",
    "\n",
    "# push feature maps through activation\n",
    "# activation \n",
    "def activation(t):\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "transformed_feature_maps = activation(feature_maps)\n",
    "\n",
    "#### downsample via pooling ####\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for feature_map in transformed_feature_maps:    \n",
    "    # move over feature map and gather patches\n",
    "    wind_featmap = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "    \n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "    # reshape into new tensor\n",
    "    max_pool.shape = (np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)))\n",
    "\n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "    \n",
    "# turn into array\n",
    "new_tensors = np.asarray(new_tensors)\n",
    "\n",
    "# reshape into final feature vector to touch fully connected layer(s), otherwise keep as is in terms of shape\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.7624475775262038e-16"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_tensors - feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Really compact version - push all tensors together for compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to do: probably not necessary for now, but intellectually appealing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naive_conv_layer:  \n",
    "    '''\n",
    "    A simple convnet module.  Here we calculate feature maps exactly one at a time, using\n",
    "    a host of nested for-loops.  This means computation will be quite slow!  However this\n",
    "    can still be used in theory as a fixed convolutional feature extractor or as a convolutional\n",
    "    layer in a conv net (where the kernels are learned).\n",
    "    '''   \n",
    "    \n",
    "    # a convolution function\n",
    "    def conv_function(self,window):\n",
    "        conv = np.sum(self.kernel*window)\n",
    "        return conv\n",
    "\n",
    "    # a pooling function\n",
    "    def pool_function(self,window):\n",
    "        pool = np.max(window)\n",
    "        return pool\n",
    "\n",
    "    # activation function\n",
    "    def activation(self,window):\n",
    "        a = np.maximum(0,window)\n",
    "        return a\n",
    "\n",
    "    # pad image with appropriate number of zeros for convolution\n",
    "    def pad_image(self,image,kernel_size):\n",
    "        odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "        pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "        image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "        image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "        return image_padded   \n",
    "\n",
    "    # sliding window function, convolution or pooling done on each window\n",
    "    def sliding_window_image(self,image,window_size,stride,func):\n",
    "        # grab image size, set container for results\n",
    "        image_size = np.shape(image)[0]\n",
    "        results = []\n",
    "\n",
    "        # slide window over input image with given window size / stride and function\n",
    "        for i in np.arange(0, image_size - window_size + 1, stride):\n",
    "            for j in np.arange(0, image_size - window_size + 1, stride):\n",
    "                # now we have a window from our image, and use the desired 'func' to process it\n",
    "                window = image[i:i+window_size,j:j+window_size]\n",
    "\n",
    "                # process using input func\n",
    "                processed_window = func(window)\n",
    "                results.append(processed_window)\n",
    "\n",
    "        # array-afy results\n",
    "        results = np.array(results)\n",
    "\n",
    "        # return results in numpy array format\n",
    "        return results\n",
    "\n",
    "    def make_feature_map(self,image,kernel):\n",
    "        # square up input\n",
    "        self.kernel = kernel\n",
    "        img_size = int((np.size(image))**(0.5))\n",
    "        image = np.reshape(image,(img_size,img_size))\n",
    "\n",
    "        # pad image appropriately\n",
    "        kernel_size = kernel.shape[0]\n",
    "        padded_image = self.pad_image(image,kernel_size)\n",
    "\n",
    "        # create feature map via convolution --> returns flattened convolution calculations\n",
    "        conv_stride = 1\n",
    "        feature_map = self.sliding_window_image(padded_image,kernel_size,conv_stride,self.conv_function)\n",
    "\n",
    "        # reshape convolution feature map into array\n",
    "        feature_map = np.reshape(feature_map,(np.shape(image)))\n",
    "\n",
    "        # now shove result through nonlinear activation\n",
    "        feature_map = self.activation(feature_map)\n",
    "\n",
    "        #### now pool / downsample feature map, first window then pool on each window\n",
    "        max_pool = self.sliding_window_image(feature_map,6,3,self.pool_function)\n",
    "\n",
    "        # reshape into new tensor\n",
    "        max_pool = np.reshape(max_pool, (int((np.size(max_pool))**(0.5)),int((np.size(max_pool))**(0.5))))\n",
    "\n",
    "        return max_pool\n",
    "    \n",
    "    # convolution layer function - here we collect all of the feature maps and package them appropriately\n",
    "    def conv_layer(self,tensor,kernels):   \n",
    "        kernel = kernels[0]\n",
    "        all_feature_maps = []\n",
    "        for image in tensor:\n",
    "            current_feat_maps = []\n",
    "            for kernel in kernels:\n",
    "                # compute feature map for current image using current convolution kernel\n",
    "                feat_map = self.make_feature_map(image,kernel)\n",
    "\n",
    "                # store feature maps of current kernel\n",
    "                current_feat_maps.append(feat_map)\n",
    "\n",
    "            # append all feature maps from current kernel to running list\n",
    "            all_feature_maps.append(current_feat_maps)\n",
    "\n",
    "        # convert to array and re-shape properly\n",
    "        all_feature_maps = np.array(all_feature_maps)\n",
    "        all_feature_maps = np.reshape(all_feature_maps,(np.shape(all_feature_maps)[0],np.prod(np.shape(all_feature_maps)[1:])),order = 'F')\n",
    "        return all_feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tensor_conv_layer:    \n",
    "    # convolution function\n",
    "    def conv_function(self,tensor_window):\n",
    "        tensor_window = np.reshape(tensor_window,(np.shape(tensor_window)[0],np.shape(tensor_window)[1]*np.shape(tensor_window)[2]))\n",
    "        t = np.dot(self.kernels,tensor_window.T)\n",
    "        return t\n",
    "\n",
    "    # pooling / downsampling parameters\n",
    "    def pool_function(self,tensor_window):\n",
    "        t = np.max(tensor_window,axis = (1,2))\n",
    "        return t\n",
    "\n",
    "    # activation \n",
    "    def activation(self,tensor_window):\n",
    "        return np.maximum(0,tensor_window)\n",
    "\n",
    "    # pad image with appropriate number of zeros for convolution\n",
    "    def pad_tensor(self,tensor,kernel_size):\n",
    "        odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "        pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "        tensor_padded = np.zeros((np.shape(tensor)[0], np.shape(tensor)[1] + 2*pad_val,np.shape(tensor)[2] + 2*pad_val))\n",
    "        tensor_padded[:,pad_val:-pad_val,pad_val:-pad_val] = tensor\n",
    "        return tensor_padded    \n",
    "    \n",
    "    # sliding window for image augmentation\n",
    "    def sliding_window_tensor(self,tensor,window_size,stride,func):\n",
    "        # grab image size, set container for results\n",
    "        image_size = np.shape(tensor)[1]\n",
    "        results = []\n",
    "        \n",
    "        # slide window over input image with given window size / stride and function\n",
    "        for i in np.arange(0, image_size - window_size + 1, stride):\n",
    "            for j in np.arange(0, image_size - window_size + 1, stride):\n",
    "                # take a window of input tensor\n",
    "                tensor_window =  tensor[:,i:i+window_size, j:j+window_size]\n",
    "                \n",
    "                # now process entire windowed tensor at once\n",
    "                tensor_window = np.array(tensor_window)\n",
    "                yo = func(tensor_window)\n",
    "\n",
    "                # store weight\n",
    "                results.append(yo)\n",
    "        \n",
    "        # re-shape properly\n",
    "        results = np.array(results)\n",
    "        results = results.swapaxes(0,1)\n",
    "        if func == self.conv_function:\n",
    "            results = results.swapaxes(1,2)\n",
    "        return results \n",
    "\n",
    "    # make feature map\n",
    "    def make_feature_tensor(self,tensor):\n",
    "        # create feature map via convolution --> returns flattened convolution calculations\n",
    "        conv_stride = 1\n",
    "        feature_tensor = self.sliding_window_tensor(tensor,self.kernel_size,conv_stride,self.conv_function) \n",
    "\n",
    "        # re-shape convolution output ---> to square of same size as original input\n",
    "        num_filters = np.shape(feature_tensor)[0]\n",
    "        num_images = np.shape(feature_tensor)[1]\n",
    "        square_dim = int((np.shape(feature_tensor)[2])**(0.5))\n",
    "        feature_tensor = np.reshape(feature_tensor,(num_filters,num_images,square_dim,square_dim))\n",
    "        \n",
    "        # shove feature map through nonlinearity\n",
    "        feature_tensor = self.activation(feature_tensor)\n",
    "\n",
    "        # pool feature map --- i.e., downsample it\n",
    "        pool_stride = 3\n",
    "        pool_window_size = 6\n",
    "        downsampled_feature_map = []\n",
    "        for t in range(np.shape(feature_tensor)[0]):\n",
    "            temp_tens = feature_tensor[t,:,:,:]\n",
    "            d = self.sliding_window_tensor(temp_tens,pool_window_size,pool_stride,self.pool_function)\n",
    "            downsampled_feature_map.append(d)\n",
    "        downsampled_feature_map = np.array(downsampled_feature_map)\n",
    "\n",
    "        # return downsampled feature map --> flattened\n",
    "        return downsampled_feature_map\n",
    "\n",
    "    # our normalization function\n",
    "    def normalize(self,data,data_mean,data_std):\n",
    "        normalized_data = (data - data_mean)/(data_std + 10**(-5))\n",
    "        return normalized_data\n",
    "\n",
    "    # convolution layer\n",
    "    def conv_layer(self,tensor,kernels):\n",
    "        #### prep input tensor #####\n",
    "        # pluck out dimensions for image-tensor reshape\n",
    "        num_images = np.shape(tensor)[0]\n",
    "        num_kernels = np.shape(kernels)[0]\n",
    "        \n",
    "        # create tensor out of input images (assumed to be stacked vertically as columns)\n",
    "        tensor = np.reshape(tensor,(np.shape(tensor)[0],int((np.shape(tensor)[1])**(0.5)),int( (np.shape(tensor)[1])**(0.5))),order = 'F')\n",
    "\n",
    "        # pad tensor\n",
    "        kernel = kernels[0]\n",
    "        self.kernel_size = np.shape(kernel)[0]\n",
    "        padded_tensor = self.pad_tensor(tensor,self.kernel_size)\n",
    "\n",
    "        #### prep kernels - reshape into array for more effecient computation ####\n",
    "        self.kernels = np.reshape(kernels,(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]))\n",
    "        \n",
    "        #### compute convolution feature maps / downsample via pooling one map at a time over entire tensor #####\n",
    "        # compute feature map for current image using current convolution kernel\n",
    "        feature_tensor = self.make_feature_tensor(padded_tensor)\n",
    "\n",
    "        feature_tensor = feature_tensor.swapaxes(0,1)\n",
    "        feature_tensor = np.reshape(feature_tensor, (np.shape(feature_tensor)[0],np.shape(feature_tensor)[1]*np.shape(feature_tensor)[2]),order = 'F')\n",
    "        \n",
    "        return feature_tensor\n",
    "    \n",
    "    ##### some supervised learning capabilities #####\n",
    "    def load_data(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def predict(self,x,w):\n",
    "        # pass input data through convolutional layer\n",
    "        x_conv = self.conv_layer(x,w[0])\n",
    "        \n",
    "        # take inner product against output of conv layer\n",
    "        value = w[1][0] + np.dot(x_conv,w[1][1:])\n",
    "        return value\n",
    "    \n",
    "    # the softmax cost function \n",
    "    def softmax(self,w):\n",
    "        cost  = np.sum(np.log(1 + np.exp((-self.y)*(self.predict(self.x,w)))))\n",
    "        return cost\n",
    "    \n",
    "    def count(self,w):\n",
    "        return 0.25*np.sum((np.sign(self.predict(self.x,w)) - self.y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.038477\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "tensor_conv_test = tensor_conv_layer()\n",
    "feature_maps_2 = tensor_conv_test.conv_layer(X,kernels)\n",
    "\n",
    "# finish timing\n",
    "timeElapsed=datetime.now()-startTime \n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:01.188999\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "tensor_conv_test = naive_conv_layer()\n",
    "feature_maps_1 = tensor_conv_test.conv_layer(X,kernels)\n",
    "\n",
    "# finish timing\n",
    "timeElapsed=datetime.now()-startTime \n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_maps_2 - new_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.7624475775262038e-16"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_maps_2 - feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8477974810349713"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_maps_1 - feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 512)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naive_version_2:\n",
    "    \n",
    "    # sliding window for image augmentation\n",
    "    def sliding_window_image(self,image, kernel_size, stride):\n",
    "        windowed_image = []\n",
    "        for i in np.arange(0, np.shape(image)[0]-kernel_size+1, stride):\n",
    "            for j in np.arange(0, np.shape(image)[1]-kernel_size+1, stride):\n",
    "                 windowed_image.append(image[i:i+kernel_size, j:j+kernel_size].flatten())\n",
    "\n",
    "        return np.array(windowed_image)\n",
    "\n",
    "    # pad image with appropriate number of zeros for convolution\n",
    "    def pad_image(self,image,kernel_size):\n",
    "        odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "        pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "        image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "        image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "        return image_padded     \n",
    "    \n",
    "    # activation function\n",
    "    def activation(self,window):\n",
    "        a = np.maximum(0,window)\n",
    "        return a\n",
    "    \n",
    "    def make_feature_map(self,image,kernel):\n",
    "        # parameters for transform\n",
    "        kernel_size = kernels[0].shape[0]\n",
    "        pool_kernel_size = 6\n",
    "        stride = 3\n",
    "    \n",
    "        # pad image with zeros\n",
    "        padded_image = self.pad_image(image,kernel_size)\n",
    "        \n",
    "       # window image\n",
    "        wind_img = sliding_window_image(padded_image,kernel_size,stride = 1)\n",
    "        \n",
    "        # make convolution feature map - via matrix multiplication over windowed tensor \n",
    "        feature_map = np.dot(wind_img,kernel.flatten()[:,np.newaxis])\n",
    "        \n",
    "        # reshape convolution feature map into array\n",
    "        feature_map = np.reshape(feature_map,(np.shape(image)))\n",
    "\n",
    "        # now shove result through nonlinear activation\n",
    "       # feature_map = self.activation(feature_map)\n",
    "\n",
    "#         #### now pool / downsample feature map, first window then pool on each window\n",
    "#         wind_featmap = sliding_window_image(feature_map,pool_kernel_size,stride = stride)\n",
    "\n",
    "#         # max pool on each collected patch\n",
    "#         max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "#         # reshape into new tensor\n",
    "#         max_pool = np.reshape(max_pool, (int((np.size(max_pool))**(0.5)),int((np.size(max_pool))**(0.5))))\n",
    "\n",
    "        return feature_map # max_pool\n",
    "\n",
    "        \n",
    "    def conv_layer(self,images,kernels):\n",
    "        #### create image tensor from input images\n",
    "        image_tensor = np.reshape(images,(np.shape(images)[0],int((np.shape(images)[1])**(0.5)),int( (np.shape(images)[1])**(0.5))),order = 'F')\n",
    "\n",
    "        #### loop over each image, shove through filters and make feature maps, then downsample and pool\n",
    "        new_tensors = []\n",
    "\n",
    "        #### loop over images\n",
    "        for image in image_tensor:\n",
    "            #### loop over kernels and construct feature map for each kernel\n",
    "            downsampled_feature_maps = []\n",
    "            for kernel in kernels:\n",
    "                downsampled_map = self.make_feature_map(image,kernel)\n",
    "                downsampled_feature_maps.append(downsampled_map)\n",
    "            \n",
    "            ## re-shape downsampled_feature_maps and store\n",
    "            new_tensors.append(downsampled_feature_maps)\n",
    "\n",
    "        # reshape new tensor properly\n",
    "        new_tensors = np.array(new_tensors)\n",
    "#         new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "#         new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "        return new_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.536918\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "tensor_conv_test = naive_version_2()\n",
    "feature_maps_3 = tensor_conv_test.conv_layer(X,kernels)\n",
    "\n",
    "# finish timing\n",
    "timeElapsed=datetime.now()-startTime \n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.6432407931151067e-16"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_maps_3 - feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naive_version_3:\n",
    "    \n",
    "    # a convolution function\n",
    "    def conv_function(self,window):\n",
    "#         conv = np.sum(self.kernel*window)\n",
    "        conv = np.dot(window.flatten(),self.kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "        return conv\n",
    "\n",
    "    # a pooling function\n",
    "    def pool_function(self,window):\n",
    "        pool = np.max(window)\n",
    "        return pool\n",
    "\n",
    "    # activation function\n",
    "    def activation(self,window):\n",
    "        a = np.maximum(0,window)\n",
    "        return a\n",
    "    \n",
    "    # pad image with appropriate number of zeros for convolution\n",
    "    def pad_image(self,image,kernel_size):\n",
    "        odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "        pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "        image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "        image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "        return image_padded          \n",
    "    \n",
    "    # sliding window function, convolution or pooling done on each window\n",
    "    def sliding_window_image(self,image,window_size,stride,func):\n",
    "        # grab image size, set container for results\n",
    "        image_size = np.shape(image)[0]\n",
    "        results = []\n",
    "\n",
    "        # slide window over input image with given window size / stride and function\n",
    "        for i in np.arange(0, image_size - window_size + 1, stride):\n",
    "            for j in np.arange(0, image_size - window_size + 1, stride):\n",
    "                # now we have a window from our image, and use the desired 'func' to process it\n",
    "                window = image[i:i+window_size,j:j+window_size]\n",
    "\n",
    "                # process using input func\n",
    "                processed_window = func(window)\n",
    "                results.append(processed_window)\n",
    "\n",
    "        # array-afy results\n",
    "        results = np.array(results)\n",
    "\n",
    "        # return results in numpy array format\n",
    "        return results\n",
    "    \n",
    "    def make_feature_map(self,image,kernel):\n",
    "        # parameters for transform\n",
    "        kernel_size = kernels[0].shape[0]\n",
    "        pool_kernel_size = 6\n",
    "        stride = 3\n",
    "    \n",
    "        # pad image with zeros\n",
    "        padded_image = self.pad_image(image,kernel_size)\n",
    "        \n",
    "        # window image\n",
    "        feature_map = self.sliding_window_image(padded_image,kernel_size,stride = 1,func = self.conv_function)\n",
    "        \n",
    "        # reshape convolution feature map into array\n",
    "        feature_map = np.reshape(feature_map,(np.shape(image)))\n",
    "        \n",
    "        # now shove result through nonlinear activation\n",
    "        feature_maps = self.activation(feature_map)\n",
    "\n",
    "#         #### now pool / downsample feature map, first window then pool on each window\n",
    "#         max_pool = self.sliding_window_image(feature_map,pool_kernel_size,stride = stride,func = self.pool_function)\n",
    "\n",
    "#         # reshape into new tensor\n",
    "#         max_pool = np.reshape(max_pool, (int((np.size(max_pool))**(0.5)),int((np.size(max_pool))**(0.5))))\n",
    "\n",
    "        return feature_map #max_pool\n",
    "        \n",
    "    def conv_layer(self,images,kernels):\n",
    "        #### create image tensor from input images\n",
    "        image_tensor = np.reshape(images,(np.shape(images)[0],int((np.shape(images)[1])**(0.5)),int( (np.shape(images)[1])**(0.5))),order = 'F')\n",
    "\n",
    "        #### loop over each image, shove through filters and make feature maps, then downsample and pool\n",
    "        new_tensors = []\n",
    "\n",
    "        #### loop over images\n",
    "        for image in image_tensor:\n",
    "            #### loop over kernels and construct feature map for each kernel\n",
    "            downsampled_feature_maps = []\n",
    "            for kernel in kernels:\n",
    "                self.kernel = kernel\n",
    "                downsampled_map = self.make_feature_map(image,kernel)\n",
    "                downsampled_feature_maps.append(downsampled_map)\n",
    "            \n",
    "            ## re-shape downsampled_feature_maps and store\n",
    "            new_tensors.append(downsampled_feature_maps)\n",
    "\n",
    "        # reshape new tensor properly\n",
    "        new_tensors = np.array(new_tensors)\n",
    "#         new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "#         new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "        return new_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.851792\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "tensor_conv_test = naive_version_3()\n",
    "feature_maps_4 = tensor_conv_test.conv_layer(X,kernels)\n",
    "\n",
    "# finish timing\n",
    "timeElapsed=datetime.now()-startTime \n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8380887752150625e-15"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_maps_3 - feature_maps_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011267652354101987"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_maps_3 - feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.106234 ,  0.0266849,  0.127836 ,  0.060995 ,  0.081582 ,\n",
       "        0.124278 ,  0.084377 ,  0.102675 ,  0.0620116,  0.0404084,\n",
       "        0.0714155,  0.0419333,  0.0180453,  0.0358355,  0.0203315,\n",
       "        0.0795479,  0.0406638,  0.0404084,  0.0714155,  0.0419333,\n",
       "        0.0132154,  0.0358355,  0.0203315,  0.0706517,  0.0460014,\n",
       "        0.0221102,  0.059471 ,  0.013469 ,  0.0124542,  0.0330392,\n",
       "        0.0172822,  0.0620124,  0.057945 ,  0.008133 ,  0.039139 ,\n",
       "        0.014233 ,  0.017027 ,  0.011437 , -0.003558 ,  0.06862  ,\n",
       "        0.0719235,  0.0345648,  0.0368504,  0.016774 ,  0.0287187,\n",
       "        0.0132159,  0.035327 ,  0.0744645,  0.0734487,  0.0345648,\n",
       "        0.043205 ,  0.016774 ,  0.0287187,  0.0254149,  0.038122 ,\n",
       "        0.0780231,  0.089205 ,  0.0317685,  0.109538 ,  0.008641 ,\n",
       "        0.0256692,  0.085392 ,  0.073194 ,  0.132411 ,  0.0620116,\n",
       "        0.0266849,  0.084632 ,  0.061504 ,  0.078023 ,  0.124278 ,\n",
       "        0.084377 ,  0.0795479,  0.0620116,  0.0266849,  0.0714155,\n",
       "        0.0353258,  0.03253  ,  0.065824 ,  0.043459 ,  0.0795479,\n",
       "        0.037869 ,  0.018298 ,  0.0714155,  0.034563 ,  0.03253  ,\n",
       "        0.0358355,  0.030245 ,  0.0706517,  0.033039 ,  0.016265 ,\n",
       "        0.059471 ,  0.01652  ,  0.016772 ,  0.0330392,  0.030245 ,\n",
       "        0.060741 ,  0.057945 ,  0.029226 ,  0.039139 ,  0.035327 ,\n",
       "        0.034565 ,  0.028465 ,  0.023382 ,  0.06862  ,  0.0719235,\n",
       "        0.029226 ,  0.034057 ,  0.035327 ,  0.034565 ,  0.028718 ,\n",
       "        0.020586 ,  0.0744645,  0.0734487,  0.026684 ,  0.043205 ,\n",
       "        0.038376 ,  0.057182 ,  0.028718 ,  0.0325309,  0.0780231,\n",
       "        0.0734487,  0.032021 ,  0.062774 ,  0.038376 ,  0.057182 ,\n",
       "        0.085392 ,  0.073194 ,  0.0780231,  0.054387 ,  0.015757 ,\n",
       "        0.084376 ,  0.061504 ,  0.075228 ,  0.125802 ,  0.083614 ,\n",
       "        0.036852 ,  0.054388 ,  0.018298 ,  0.050067 ,  0.034563 ,\n",
       "        0.03253  ,  0.065824 ,  0.043459 ,  0.048797 ,  0.054388 ,\n",
       "        0.018298 ,  0.04168  ,  0.034563 ,  0.03253  ,  0.032278 ,\n",
       "        0.030245 ,  0.048797 ,  0.03736  ,  0.021094 ,  0.04168  ,\n",
       "        0.023127 ,  0.016772 ,  0.032278 ,  0.030245 ,  0.045493 ,\n",
       "        0.032276 ,  0.029226 ,  0.029736 ,  0.035327 ,  0.034565 ,\n",
       "        0.028465 ,  0.023382 ,  0.039393 ,  0.032276 ,  0.029226 ,\n",
       "        0.046001 ,  0.035327 ,  0.034565 ,  0.028718 ,  0.020586 ,\n",
       "        0.04168  ,  0.04727  ,  0.026684 ,  0.046001 ,  0.038376 ,\n",
       "        0.057182 ,  0.028718 ,  0.020586 ,  0.04168  ,  0.04727  ,\n",
       "        0.032021 ,  0.05642  ,  0.038376 ,  0.057182 ,  0.060232 ,\n",
       "        0.063027 ,  0.03431  ,  0.037868 ,  0.006608 ,  0.084376 ,\n",
       "        0.02211  ,  0.043458 ,  0.125802 ,  0.083106 ,  0.018044 ,\n",
       "        0.054388 ,  0.008641 ,  0.033038 ,  0.009149 ,  0.029481 ,\n",
       "        0.041935 ,  0.026686 ,  0.048797 ,  0.054388 ,  0.010166 ,\n",
       "        0.04168  ,  0.019316 ,  0.029481 ,  0.026177 ,  0.012961 ,\n",
       "        0.048797 ,  0.03736  ,  0.021094 ,  0.04168  ,  0.023127 ,\n",
       "        0.022874 ,  0.026177 ,  0.015249 ,  0.045493 ,  0.032276 ,\n",
       "        0.021094 ,  0.029736 ,  0.024145 ,  0.030244 ,  0.017537 ,\n",
       "        0.017283 ,  0.039393 ,  0.032276 ,  0.01347  ,  0.046001 ,\n",
       "        0.024145 ,  0.030244 ,  0.02821  ,  0.017283 ,  0.04168  ,\n",
       "        0.04727  ,  0.009404 ,  0.046001 ,  0.029734 ,  0.055148 ,\n",
       "        0.02821  ,  0.012199 ,  0.04168  ,  0.04727  ,  0.010167 ,\n",
       "        0.05642  ,  0.029734 ,  0.055148 ,  0.054132 ,  0.033295 ,\n",
       "        0.03431  ,  0.035073 ,  0.017282 ,  0.08641  ,  0.031769 ,\n",
       "        0.039393 ,  0.128853 ,  0.085648 ,  0.016774 ,  0.014486 ,\n",
       "        0.017282 ,  0.017537 ,  0.018045 ,  0.011945 ,  0.028465 ,\n",
       "        0.021094 ,  0.009403 ,  0.015503 ,  0.018807 ,  0.008133 ,\n",
       "        0.019569 ,  0.023382 ,  0.008388 ,  0.010676 ,  0.004575 ,\n",
       "        0.016266 ,  0.018807 ,  0.007625 ,  0.021856 ,  0.023382 ,\n",
       "        0.009149 ,  0.013469 ,  0.007626 ,  0.016266 ,  0.013978 ,\n",
       "        0.013216 ,  0.021856 ,  0.019569 ,  0.021349 ,  0.019569 ,\n",
       "        0.007626 ,  0.006607 ,  0.013724 ,  0.013216 ,  0.011691 ,\n",
       "        0.012962 ,  0.021349 ,  0.019569 ,  0.004575 ,  0.021603 ,\n",
       "        0.012199 ,  0.031768 ,  0.025415 ,  0.032276 ,  0.029988 ,\n",
       "        0.011944 ,  0.014487 ,  0.021603 ,  0.010167 ,  0.034819 ,\n",
       "        0.025415 ,  0.032276 ,  0.043968 ,  0.033295 ,  0.023637 ,\n",
       "        0.037359 ,  0.017282 ,  0.08768  ,  0.031769 ,  0.039393 ,\n",
       "        0.130885 ,  0.087172 ,  0.015757 ,  0.031515 ,  0.017791 ,\n",
       "        0.013977 ,  0.018045 ,  0.036089 ,  0.023635 ,  0.02084  ,\n",
       "        0.012708 ,  0.015503 ,  0.018807 ,  0.009403 ,  0.022619 ,\n",
       "        0.023382 ,  0.008388 ,  0.010676 ,  0.015503 ,  0.016266 ,\n",
       "        0.018807 ,  0.009403 ,  0.022619 ,  0.023382 ,  0.009149 ,\n",
       "        0.011691 ,  0.015503 ,  0.016266 ,  0.020332 ,  0.016265 ,\n",
       "        0.019823 ,  0.019569 ,  0.021349 ,  0.022873 ,  0.017789 ,\n",
       "        0.010166 ,  0.020332 ,  0.016265 ,  0.011691 ,  0.011436 ,\n",
       "        0.021349 ,  0.022873 ,  0.017789 ,  0.01525  ,  0.019061 ,\n",
       "        0.03253  ,  0.011691 ,  0.021095 ,  0.039393 ,  0.028719 ,\n",
       "        0.013216 ,  0.01525  ,  0.007624 ,  0.032531 ,  0.010675 ,\n",
       "        0.021095 ,  0.039393 ,  0.028719 ,  0.022365 ,  0.037359 ,\n",
       "        0.006607 ,  0.08768  ,  0.021095 ,  0.038376 ,  0.130885 ,\n",
       "        0.087934 ,  0.015757 ,  0.031515 ,  0.017791 ,  0.012454 ,\n",
       "        0.021095 ,  0.036089 ,  0.018298 ,  0.013723 ,  0.012708 ,\n",
       "        0.012708 ,  0.018807 ,  0.009403 ,  0.022619 ,  0.012707 ,\n",
       "        0.01042  ,  0.01779  ,  0.015503 ,  0.016011 ,  0.018807 ,\n",
       "        0.012961 ,  0.022619 ,  0.012707 ,  0.01042  ,  0.01779  ,\n",
       "        0.015503 ,  0.016011 ,  0.020332 ,  0.016265 ,  0.02211  ,\n",
       "        0.014486 ,  0.012961 ,  0.022873 ,  0.017789 ,  0.010166 ,\n",
       "        0.020332 ,  0.016265 ,  0.02211  ,  0.014486 ,  0.01347  ,\n",
       "        0.022873 ,  0.017789 ,  0.003049 ,  0.019061 ,  0.03253  ,\n",
       "        0.016519 ,  0.010165 ,  0.043458 ,  0.032021 ,  0.008895 ,\n",
       "        0.003049 ,  0.007624 ,  0.03253  ,  0.009404 ,  0.008132 ,\n",
       "        0.043458 ,  0.032021 ,  0.008895 ,  0.028465 ,  0.033802 ,\n",
       "        0.117162 ,  0.066842 ,  0.058709 ,  0.145627 ,  0.087934 ,\n",
       "        0.023127 ,  0.024398 ,  0.033802 ,  0.010675 ,  0.029227 ,\n",
       "        0.033802 ,  0.020333 ,  0.022366 ,  0.013216 ,  0.018299 ,\n",
       "        0.015249 ,  0.00432  ,  0.008387 ,  0.01042  ,  0.01042  ,\n",
       "        0.01779  ,  0.015503 ,  0.018299 ,  0.024398 ,  0.012961 ,\n",
       "        0.018807 ,  0.010674 ,  0.01042  ,  0.01779  ,  0.015503 ,\n",
       "        0.016011 ,  0.024398 ,  0.020333 ,  0.02211  ,  0.014486 ,\n",
       "        0.011946 ,  0.01652  ,  0.015249 ,  0.0061   ,  0.018044 ,\n",
       "        0.020333 ,  0.02211  ,  0.014486 ,  0.011946 ,  0.009149 ,\n",
       "        0.015503 ,  0.0061   ,  0.013215 ,  0.026939 ,  0.016519 ,\n",
       "        0.010165 ,  0.043458 ,  0.03736  ,  0.015503 ,  0.006607 ,\n",
       "        0.012707 ,  0.026939 ,  0.007879 ,  0.005338 ,  0.043458 ,\n",
       "        0.03736  ,  0.007623 ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_maps_3[0,:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

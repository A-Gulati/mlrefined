{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal as sig\n",
    "\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "from mlrefined_libraries import convnets_library as convlib\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import multilayer_perceptron_library as network_lib\n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import grad as compute_grad   \n",
    "\n",
    "import autograd.numpy as np\n",
    "import numpy as npo\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import csv\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime \n",
    "\n",
    "#this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "\n",
    "def ScipyConv(image, kernel):\n",
    "    \n",
    "    # flip kernel\n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "    \n",
    "    # compute convolution\n",
    "    conv = signal.convolve2d(image, kernel, boundary='fill', fillvalue=0, mode='same')\n",
    "    return conv  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most naive image version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### parameters for naive convolution ###\n",
    "conv_function = lambda window: np.sum(kernel*window)\n",
    "\n",
    "# pooling / downsampling parameters\n",
    "pool_function = lambda window: np.max(window) \n",
    "\n",
    "# activation \n",
    "activation = lambda window: np.maximum(0,window)\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_image(image,kernel_size):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "    image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "    image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "    return image_padded   \n",
    "\n",
    "def sliding_window(image,window_size,stride,func):\n",
    "    # grab image size, set container for results\n",
    "    image_size = np.shape(image)[0]\n",
    "    results = []\n",
    "    \n",
    "    # slide window over input image with given window size / stride and function\n",
    "    for i in np.arange(0, image_size - window_size + 1, stride):\n",
    "        for j in np.arange(0, image_size - window_size + 1, stride):\n",
    "            # now we have a window from our image, and use the desired 'func' to process it\n",
    "            window = image[i:i+window_size,j:j+window_size]\n",
    "            \n",
    "            # process using input func\n",
    "            processed_window = func(window)\n",
    "            results.append(processed_window)\n",
    "    \n",
    "    # array-afy results\n",
    "    results = np.array(results)\n",
    "    \n",
    "    # re-shape into square window (perhaps smaller if used for pooling)\n",
    "    new_size = int(np.size(results)**(0.5))\n",
    "    results = np.reshape(results,(new_size,new_size))\n",
    "    \n",
    "    # return results in numpy array format\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_feature_map(image,kernel):\n",
    "    # pad image appropriately\n",
    "    kernel_size = kernel.shape[0]\n",
    "    padded_image = pad_image(image,kernel_size)\n",
    "    \n",
    "    # create feature map via convolution\n",
    "    conv_stride = 1\n",
    "    feature_map = sliding_window(padded_image,kernel_size,conv_stride,conv_function)\n",
    "        \n",
    "    # shove feature map through nonlinearity\n",
    "    feature_map = activation(feature_map)\n",
    "\n",
    "    # pool feature map --- i.e., downsample it\n",
    "    pool_window_size = 2\n",
    "    pool_stride = 2\n",
    "    downsampled_feature_map = sliding_window(feature_map,pool_window_size,pool_stride,pool_function)\n",
    " \n",
    "    # return downsampled feature map\n",
    "    return downsampled_feature_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = np.random.randn(15,15)\n",
    "kernel = np.random.randn(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run image through simple convolution layer network\n",
    "feature_map = make_feature_map(image,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline = ScipyConv(image,kernel)\n",
    "baseline = activation(baseline)\n",
    "pool_window_size = 2\n",
    "pool_stride = 2\n",
    "baseline = sliding_window(baseline,pool_window_size,pool_stride,pool_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.1639146264180419e-15"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(feature_map - baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenated image version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sliding window for image augmentation\n",
    "def sliding_window_image(image, kernel, stride):\n",
    "    windowed_image = []\n",
    "    for i in np.arange(0, np.shape(image)[0]-kernel.shape[0]+1, stride):\n",
    "        for j in np.arange(0, np.shape(image)[1]-kernel.shape[1]+1, stride):\n",
    "             windowed_image.append(image[i:i+kernel.shape[0], j:j+kernel.shape[1]].flatten())\n",
    "            \n",
    "    return np.array(windowed_image)\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_image(image,kernel_size):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    val = kernel_size[0]\n",
    "    pad_val = np.argwhere(odd_nums == val)[0][0]\n",
    "    image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "    image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "    return image_padded          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate test image and kernel\n",
    "image = np.random.randn(5,5)\n",
    "kernel = np.ones((3,3))\n",
    "kernel_size = kernel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad image\n",
    "padded_image = pad_image(image,kernel_size)\n",
    "\n",
    "# window image\n",
    "wind_img = sliding_window_image(padded_image,kernel,stride = 1)\n",
    "\n",
    "# produce matrix multiplication convolution \n",
    "conv2 = np.dot(wind_img,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "# reshape convolution into array\n",
    "conv2.shape = (np.shape(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5)\n",
      "(7, 7)\n",
      "(25, 9)\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(image))\n",
    "print(np.shape(padded_image))\n",
    "print(np.shape(wind_img))\n",
    "print(np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### baseline convolution #####\n",
    "conv1 = ScipyConv(image,kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.84611094726e-15\n",
      "(5, 5) (5, 5)\n"
     ]
    }
   ],
   "source": [
    "#### compare convolutions ####\n",
    "error = np.linalg.norm(conv1 - conv2)\n",
    "print (error)\n",
    "print (np.shape(conv1),np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# activation \n",
    "def activation(t):\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "# output of activation\n",
    "a_conv = activation(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pool operation\n",
    "kernel2 = np.ones((2,2))\n",
    "wind_conv = sliding_window(a_conv,kernel2,stride = 2)\n",
    "\n",
    "# max pooling\n",
    "max_pool = np.max(wind_conv,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(wind_conv))\n",
    "print (np.shape(max_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# back to an image\n",
    "max_pool.shape = (int(np.size(max_pool)**(0.5)),int(np.size(max_pool)**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(max_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sliding window for image augmentation\n",
    "def sliding_window_tensor(tensor, kernel, stride):\n",
    "    windowed_tensor = []\n",
    "    for i in np.arange(0, np.shape(tensor)[1]-kernel.shape[0]+1, stride):\n",
    "        for j in np.arange(0, np.shape(tensor)[2]-kernel.shape[1]+1, stride):\n",
    "            sock = copy.deepcopy(tensor[:,i:i+kernel.shape[0], j:j+kernel.shape[1]])\n",
    "            windowed_tensor.append(sock)\n",
    "    \n",
    "    # re-shape properly\n",
    "    windowed_tensor = np.array(windowed_tensor)\n",
    "    windowed_tensor = windowed_tensor.swapaxes(0,1)    \n",
    "    windowed_tensor = np.reshape(windowed_tensor,(np.shape(windowed_tensor)[0]*np.shape(windowed_tensor)[1],np.shape(windowed_tensor)[2]*np.shape(windowed_tensor)[3]))   \n",
    "    return windowed_tensor\n",
    "\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_tensor(tensor,kernel):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    val = kernel.shape[0]\n",
    "    pad_val = np.argwhere(odd_nums == val)[0][0]\n",
    "    tensor_padded = np.zeros((np.shape(tensor)[0], np.shape(tensor)[1] + 2*pad_val,np.shape(tensor)[2] + 2*pad_val))\n",
    "    tensor_padded[:,pad_val:-pad_val,pad_val:-pad_val] = tensor\n",
    "    return tensor_padded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create test tensor\n",
    "tensor = np.random.randn(3,5,5)\n",
    "kernel = np.ones((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pad tensor\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "# # produce matrix multiplication convolution \n",
    "conv2 = np.dot(wind_tensor,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "# # reshape convolution into array\n",
    "conv2.shape = (np.shape(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5, 5)\n",
      "(3, 7, 7)\n",
      "(75, 9)\n",
      "(3, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(tensor))\n",
    "print(np.shape(padded_tensor))\n",
    "print(np.shape(wind_tensor))\n",
    "print(np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### baseline convolution #####\n",
    "convs = []\n",
    "for i in range(np.shape(tensor)[0]):\n",
    "    conv1 = ScipyConv(tensor[i,:,:],kernel)\n",
    "    convs.append(conv1)\n",
    "convs = np.asarray(convs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.53553677697e-15\n",
      "(3, 5, 5) (3, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "#### compare convolutions ####\n",
    "error = np.linalg.norm(convs - conv2)\n",
    "print (error)\n",
    "print (np.shape(convs),np.shape(conv2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output of activation\n",
    "a_conv = activation(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pool operation\n",
    "kernel2 = np.ones((2,2))\n",
    "wind_conv = sliding_window_tensor(a_conv,kernel2,stride = 2)\n",
    "\n",
    "# max pooling\n",
    "max_pool = np.max(wind_conv,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 4)\n",
      "(12,)\n"
     ]
    }
   ],
   "source": [
    "print (np.shape(wind_conv))\n",
    "print (np.shape(max_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape into tensor\n",
    "max_pool.shape = (np.shape(tensor)[0],int(np.shape(wind_conv)[1]**(0.5)),int(np.shape(wind_conv)[1]**(0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(max_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with tensor and multiple kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create test tensor\n",
    "tensor = np.random.randn(3,28,28)\n",
    "kernels = np.random.randn(8,3,3)\n",
    "kernel = kernels[0]\n",
    "\n",
    "# pad tensor\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.008210\n"
     ]
    }
   ],
   "source": [
    "#### baseline convolution #####\n",
    "convs = []\n",
    "for kernel in kernels:\n",
    "    temp = []\n",
    "    for i in range(np.shape(tensor)[0]):\n",
    "        conv1 = ScipyConv(tensor[i,:,:],kernel)\n",
    "        temp.append(conv1)\n",
    "    temp = np.asarray(temp)\n",
    "    convs.append(temp)\n",
    "convs = np.asarray(convs)\n",
    "\n",
    "##### use tensor calculation from above ######\n",
    "\n",
    "startTime= datetime.now() \n",
    "\n",
    "conv2 = []\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "for kernel in kernels:\n",
    "    # # produce matrix multiplication convolution \n",
    "    conv = np.dot(wind_tensor,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "    # # reshape convolution into array\n",
    "    conv.shape = (np.shape(tensor))\n",
    "    conv = np.asarray(conv)\n",
    "    conv2.append(conv)\n",
    "conv2 = np.asarray(conv2)\n",
    "\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.000375\n"
     ]
    }
   ],
   "source": [
    "# # SUPER COMPACT VERSION\n",
    "# # produce matrix multiplication convolution \n",
    "num_kernels = np.shape(kernels)[0]\n",
    "\n",
    "startTime= datetime.now() \n",
    "\n",
    "conv3 = np.dot(wind_tensor,kernels.reshape(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]).T).T\n",
    "\n",
    "# # reshape convolution into array\n",
    "a = np.shape(tensor)\n",
    "a = list(a)\n",
    "a.insert(0,num_kernels)\n",
    "a = tuple(a)\n",
    "conv3.shape = a\n",
    "\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.95018652155e-14\n",
      "(8, 3, 28, 28) (8, 3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "#### compare convolutions  - either scipy or one kernel at a time ####\n",
    "error = np.linalg.norm(conv2 - convs)\n",
    "print (error)\n",
    "print (np.shape(convs),np.shape(conv3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of convolution we have `num_kernels` number of feature maps for our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 28, 28)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to shove through activation and pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output of activation\n",
    "transformed_feature_maps = activation(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 28, 28)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(transformed_feature_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pool operation\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for feature_map in transformed_feature_maps:\n",
    "    # move over feature map and gather patches\n",
    "    wind_conv = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "    \n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_conv,axis = 1)\n",
    "    \n",
    "    # reshape into new tensor\n",
    "    max_pool.shape = (np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)))\n",
    "    \n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "    \n",
    "# turn into array\n",
    "new_tensors = np.asarray(new_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3, 8, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(new_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step - as we feed into fully connected network component, make sure everything is reshaped correctly.  What the final output shape should be - one long vectorized sequence of 'feature maps' for each input image.  So here we are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    }
   ],
   "source": [
    "# reshape into final feature vector to touch fully connected layer(s)\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = new_tensors.reshape(np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]*np.shape(new_tensors)[3]).T\n",
    "print (np.shape(new_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All together we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 3)\n"
     ]
    }
   ],
   "source": [
    "# create test tensor\n",
    "tensor = np.random.randn(3,28,28)\n",
    "kernels = np.random.randn(8,3,3)\n",
    "kernel = kernels[0]\n",
    "\n",
    "# pad tensor\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "#### create convolution feature maps ####\n",
    "feature_maps = np.dot(wind_tensor,kernels.reshape(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]).T).T\n",
    "\n",
    "# reshape feature maps back into arrays\n",
    "shapes = np.shape(tensor)\n",
    "shapes = list(shapes)\n",
    "shapes.insert(0,num_kernels)\n",
    "shapes = tuple(shapes)\n",
    "feature_maps.shape = shapes\n",
    "\n",
    "# push feature maps through activation\n",
    "transformed_feature_maps = activation(feature_maps)\n",
    "\n",
    "#### downsample via pooling ####\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for feature_map in transformed_feature_maps:\n",
    "    # move over feature map and gather patches\n",
    "    wind_conv = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "    \n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_conv,axis = 1)\n",
    "    \n",
    "    # reshape into new tensor\n",
    "    max_pool.shape = (np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)))\n",
    "    \n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "    \n",
    "# turn into array\n",
    "new_tensors = np.asarray(new_tensors)\n",
    "\n",
    "# reshape into final feature vector to touch fully connected layer(s)\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = new_tensors.reshape(np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]*np.shape(new_tensors)[3]).T\n",
    "print (np.shape(new_tensors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test transformation on face images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data, transform via original method, transform via new method, compare features to make sure everything looks good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " def load_data(datapath):\n",
    "    # load in data\n",
    "    data = np.loadtxt(datapath,delimiter = ',')\n",
    "\n",
    "    # import data and reshape appropriately\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    y.shape = (len(y),1)\n",
    "    \n",
    "    X_square = np.zeros((len(y),28,28))\n",
    "    for i in range(0,len(y)):\n",
    "        X_square[i,:,:] = np.reshape(X[i,:],(28,28),1)\n",
    "    \n",
    "    # pad data with ones for more compact gradient computation\n",
    "    o = np.ones((np.shape(X)[0],1))\n",
    "    X = np.concatenate((o,X),axis = 1)\n",
    "    X = X.T\n",
    "    \n",
    "    return X,X_square,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "datapath = '../../mlrefined_datasets/convnet_datasets/feat_face_data.csv'\n",
    "X,X_square, y = load_data(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_square = X_square[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load kernels\n",
    "kernels = convlib.image_viz.load_kernels()\n",
    "\n",
    "# params\n",
    "sliding_window_size = (6,6) \n",
    "stride=3\n",
    "pooling_func= 'max'\n",
    "\n",
    "# get number of images in the dataset\n",
    "num_images = np.shape(X_square)[0]\n",
    "        \n",
    "# a test run to find the number of features with the params above\n",
    "test = convlib.image_viz.make_feat(X_square[0,:,:], kernels, sliding_window_size=sliding_window_size, stride=stride)\n",
    "num_features = np.shape(test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:00.343674\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "# run old method\n",
    "feat = []\n",
    "for i in range(0,num_images):\n",
    "    # extract features\n",
    "    f = convlib.image_viz.make_feat(X_square[i,:,:], kernels, sliding_window_size=sliding_window_size,\n",
    "                                            stride=stride, pooling_func=pooling_func) \n",
    "    # store it\n",
    "    feat.append(f)\n",
    "    \n",
    "# convert to array\n",
    "feat = np.asarray(feat)\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New way - non-compact image version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-make original exposing all looping structures etc.,\n",
    "\n",
    "Far too slow - takes over a minute for just 4000 images - can't use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy over test kernels\n",
    "new_kernels = []\n",
    "kernels = convlib.image_viz.load_kernels()\n",
    "for ind, kernel in kernels.items():\n",
    "    new_kernels.append(kernel)\n",
    "new_kernels = np.asarray(new_kernels)\n",
    "kernels = copy.deepcopy(new_kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign tensor name\n",
    "tensor = copy.deepcopy(X_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:05.909985\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime = datetime.now() \n",
    "\n",
    "# sliding window for image augmentation\n",
    "def sliding_window_image(image, kernel_size, stride):\n",
    "    windowed_image = []\n",
    "    for i in np.arange(0, np.shape(image)[0]-kernel_size+1, stride):\n",
    "        for j in np.arange(0, np.shape(image)[1]-kernel_size+1, stride):\n",
    "             windowed_image.append(image[i:i+kernel_size, j:j+kernel_size].flatten())\n",
    "            \n",
    "    return np.array(windowed_image)\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_image(image,kernel_size):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "    image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "    image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "    return image_padded          \n",
    "\n",
    "#### loop over each image, shove through filters and make feature maps, then downsample and pool\n",
    "new_tensors = []\n",
    "kernel_size = kernels[0].shape[0]\n",
    "pool_kernel_size = 6\n",
    "stride = 3\n",
    "\n",
    "#### loop over images\n",
    "for image in tensor:\n",
    "    # pad image with zeros\n",
    "    padded_image = pad_image(image,kernel_size)\n",
    "\n",
    "    #### loop over kernels and construct feature map for each kernel\n",
    "    downsampled_feature_maps = []\n",
    "    for kernel in kernels:\n",
    "        # window image\n",
    "        wind_img = sliding_window_image(padded_image,kernel_size,stride = 1)\n",
    "    \n",
    "        # make convolution feature map - via matrix multiplication over windowed tensor \n",
    "        feature_map = np.dot(wind_img,kernel.flatten()[:,np.newaxis])\n",
    "        \n",
    "        # reshape convolution feature map into array\n",
    "        feature_map = np.reshape(feature_map,(np.shape(image)))\n",
    "\n",
    "        # now shove result through nonlinear activation\n",
    "        feature_map = activation(feature_map)\n",
    "\n",
    "        #### now pool / downsample feature map, first window then pool on each window\n",
    "        wind_featmap = sliding_window_image(feature_map,pool_kernel_size,stride = stride)\n",
    "\n",
    "        # max pool on each collected patch\n",
    "        max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "        # reshape into new tensor\n",
    "        max_pool = np.reshape(max_pool, (int((np.size(max_pool))**(0.5)),int((np.size(max_pool))**(0.5))))\n",
    "\n",
    "        # reshape into new downsampled pooled feature map\n",
    "        downsampled_feature_maps.append(max_pool)\n",
    "        \n",
    "    ## re-shape downsampled_feature_maps and store\n",
    "    new_tensors.append(downsampled_feature_maps)\n",
    "\n",
    "# reshape new tensor properly\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0451804796210617e-15"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_tensors - feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New way - non-compact tensor version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A somewhat effecient version of the feature transform code that is still somewhat understandable, about 4 times faster than most naive version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert kernel dictionary to tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy over test kernels\n",
    "new_kernels = []\n",
    "kernels = convlib.image_viz.load_kernels()\n",
    "for ind, kernel in kernels.items():\n",
    "    new_kernels.append(kernel)\n",
    "new_kernels = np.asarray(new_kernels)\n",
    "kernels = copy.deepcopy(new_kernels)\n",
    "\n",
    "# assign tensor name\n",
    "tensor = X_square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:08.067013\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "# activation \n",
    "def activation(t):\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "# # normalize windows since they touch weights\n",
    "# a_means = np.mean(wind_tensor,axis = 0)\n",
    "# a_stds = np.std(wind_tensor,axis = 0)\n",
    "# wind_tensor = normalize(wind_tensor,a_means,a_stds)\n",
    "\n",
    "#### compute convolution feature maps / downsample via pooling one map at a time over entire tensor #####\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for kernel in kernels:\n",
    "    #### make convolution feature map - via matrix multiplication over windowed tensor \n",
    "    feature_map = np.dot(wind_tensor,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "    # reshape convolution feature map into array\n",
    "    feature_map = np.reshape(feature_map,np.shape(tensor))\n",
    "\n",
    "    # now shove result through nonlinear activation\n",
    "    feature_map = activation(feature_map)\n",
    "\n",
    "    #### now pool / downsample feature map, first window then pool on each window\n",
    "    wind_featmap = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "\n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "    # reshape into new tensor\n",
    "    max_pool = np.reshape(max_pool,(np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5))))\n",
    "\n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "\n",
    "# turn into array\n",
    "new_tensors = np.array(new_tensors)\n",
    "\n",
    "# reshape into final feature vector to touch fully connected layer(s), otherwise keep as is in terms of shape\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1149511218721878e-14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_tensors - feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New way - compact tensor version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More compact version - all kernel multiplications done at once - strangely is a bit slower than the one above, all the re-shaping must not be worth it, at least for this instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elpased (hh:mm:ss.ms) 0:00:07.301212\n"
     ]
    }
   ],
   "source": [
    "# start timer\n",
    "startTime= datetime.now() \n",
    "\n",
    "# pad tensor\n",
    "kernel = kernels[0]\n",
    "num_kernels = np.shape(kernels)[0]\n",
    "padded_tensor = pad_tensor(tensor,kernel)\n",
    "\n",
    "# window tensor\n",
    "wind_tensor = sliding_window_tensor(padded_tensor,kernel,stride = 1)\n",
    "\n",
    "#### create convolution feature maps ####\n",
    "feature_maps = np.dot(wind_tensor,kernels.reshape(np.shape(kernels)[0],np.shape(kernels)[1]*np.shape(kernels)[2]).T).T\n",
    "\n",
    "# reshape feature maps back into arrays\n",
    "shapes = np.shape(tensor)\n",
    "shapes = list(shapes)\n",
    "shapes.insert(0,num_kernels)\n",
    "shapes = tuple(shapes)\n",
    "feature_maps.shape = shapes\n",
    "\n",
    "# push feature maps through activation\n",
    "# activation \n",
    "def activation(t):\n",
    "    return np.maximum(0,t)\n",
    "\n",
    "transformed_feature_maps = activation(feature_maps)\n",
    "\n",
    "#### downsample via pooling ####\n",
    "kernel2 = np.ones((6,6))\n",
    "stride = 3\n",
    "new_tensors = []\n",
    "for feature_map in transformed_feature_maps:    \n",
    "    # move over feature map and gather patches\n",
    "    wind_featmap = sliding_window_tensor(feature_map,kernel2,stride = stride)\n",
    "    \n",
    "    # max pool on each collected patch\n",
    "    max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "    # reshape into new tensor\n",
    "    max_pool.shape = (np.shape(tensor)[0],int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)),int((np.shape(max_pool)[0]/float(np.shape(tensor)[0]))**(0.5)))\n",
    "\n",
    "    # reshape into new downsampled pooled feature map\n",
    "    new_tensors.append(max_pool)\n",
    "    \n",
    "# turn into array\n",
    "new_tensors = np.asarray(new_tensors)\n",
    "\n",
    "# reshape into final feature vector to touch fully connected layer(s), otherwise keep as is in terms of shape\n",
    "new_tensors = new_tensors.swapaxes(0,1)\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "\n",
    "# time for measurment\n",
    "timeElapsed=datetime.now()-startTime \n",
    "\n",
    "print('Time elpased (hh:mm:ss.ms) {}'.format(timeElapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4085930089667896e-14"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(new_tensors - feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Really compact version - push all tensors together for compute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to do: probably not necessary for now, but intellectually appealing "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

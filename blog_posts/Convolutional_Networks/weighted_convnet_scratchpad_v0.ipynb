{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import signal as sig\n",
    "\n",
    "# imports from custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "from mlrefined_libraries import convnets_library as convlib\n",
    "from mlrefined_libraries import basics_library as baslib\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import multilayer_perceptron_library as network_lib\n",
    "from autograd import grad as compute_grad  \n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import grad as compute_grad   \n",
    "import numpy as npo\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import csv\n",
    "import pickle\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "from datetime import datetime \n",
    "\n",
    "#this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in dataset\n",
    "datapath = '../../mlrefined_datasets/convnet_datasets/feat_face_data.csv'\n",
    "data = np.loadtxt(datapath,delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contrast normalize images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract input tensor\n",
    "tensor = data[:,:-1]\n",
    "y = data[:,-1:]\n",
    "\n",
    "# contrast normalize image data\n",
    "def contrast_normalize(data):\n",
    "    data_means = np.mean(data,axis = 0)\n",
    "    data = data - data_means\n",
    "    data_stds = np.std(data,axis = 0)\n",
    "    data = data/data_stds\n",
    "    return data\n",
    "\n",
    "# contrast normalize the input \n",
    "tensor_decontrast = contrast_normalize(tensor.T).T\n",
    "\n",
    "# make new data based on fixed kernel convolutions\n",
    "new_data = np.concatenate((tensor_decontrast,y),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a few points for testing\n",
    "ind = np.random.permutation(len(new_data))\n",
    "data_train = new_data[ind[:10],:]\n",
    "x = data_train[:,:-1]\n",
    "y = data_train[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pluck out a few datapoints for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusting gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to be careful about how we shape tensors here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gradient descent function\n",
    "def gradient_descent(g,w,alpha,max_its,version,**kwargs):       \n",
    "    # compute gradient function\n",
    "    grad = compute_grad(g)\n",
    "    \n",
    "    # flatten the input function, create gradient based on flat function\n",
    "    w_unflat = copy.deepcopy(w)\n",
    "    g_flat, unflatten, w = flatten_func(g, w)\n",
    "\n",
    "    # record history\n",
    "    w_hist = []\n",
    "    w_hist.append(w_unflat)\n",
    "\n",
    "    # over the line\n",
    "    for k in range(max_its):   \n",
    "        # plug in value into func and derivative\n",
    "        grad_eval = grad(w_unflat)\n",
    "        \n",
    "        # flatten gradient for descent step\n",
    "        grad_eval, _ = flatten(grad_eval)\n",
    "\n",
    "        ### normalized or unnormalized descent step? ###\n",
    "        if version == 'normalized':\n",
    "            grad_norm = np.linalg.norm(grad_eval)\n",
    "            if grad_norm == 0:\n",
    "                grad_norm += 10**-6*np.sign(2*np.random.rand(1) - 1)\n",
    "            grad_eval /= grad_norm\n",
    "\n",
    "        # take descent step \n",
    "        w = w - alpha*grad_eval\n",
    "\n",
    "        # unflatten weight update for storing\n",
    "        w_unflat = unflatten(w)\n",
    "        \n",
    "        # store weight update\n",
    "        w_hist.append(w_unflat)\n",
    "\n",
    "    return w_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our naive convolution functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a nonlinear activation function \n",
    "def activation(t):\n",
    "    # a relu function\n",
    "    nonlinearity = np.maximum(0,t)  # default is the relu function\n",
    "    return nonlinearity\n",
    "\n",
    "# sliding window for image augmentation\n",
    "def sliding_window_image(image, kernel_size, stride):\n",
    "    windowed_image = []\n",
    "    for i in np.arange(0, np.shape(image)[0]-kernel_size+1, stride):\n",
    "        for j in np.arange(0, np.shape(image)[1]-kernel_size+1, stride):\n",
    "             windowed_image.append(image[i:i+kernel_size, j:j+kernel_size].flatten())\n",
    "            \n",
    "    return np.array(windowed_image)\n",
    "\n",
    "# pad image with appropriate number of zeros for convolution\n",
    "def pad_image(image,kernel_size):\n",
    "    odd_nums = np.array([int(2*n + 1) for n in range(100)])\n",
    "    pad_val = np.argwhere(odd_nums == kernel_size)[0][0]\n",
    "    image_padded = np.zeros((np.shape(image) + 2*pad_val))\n",
    "    image_padded[pad_val:-pad_val,pad_val:-pad_val] = image\n",
    "    return image_padded          \n",
    "\n",
    "def conv_layer(data,kernels):\n",
    "    # loop over input and reshape to be square\n",
    "    image_tensor = np.zeros((len(y),28,28))\n",
    "    for i in range(0,np.shape(data)[0]):\n",
    "        image_tensor[i,:,:] = np.reshape(data[i,:],(28,28),1)\n",
    "        \n",
    "    ### loop over images, produce convolution feature maps, downsample\n",
    "    new_tensors = []\n",
    "    kernel_size = kernels[0].shape[0]\n",
    "    kernel_stride = 1\n",
    "    pool_kernel_size = 6\n",
    "    pool_stride = 3\n",
    "    for image in image_tensor:\n",
    "        # pad image with zeros\n",
    "        padded_image = pad_image(image,kernel_size)\n",
    "\n",
    "        #### loop over kernels and construct feature map for each kernel\n",
    "        downsampled_feature_maps = []\n",
    "        for kernel in kernels:\n",
    "            # window image\n",
    "            wind_img = sliding_window_image(padded_image,kernel_size,stride = kernel_stride)\n",
    "\n",
    "            # make convolution feature map - via matrix multiplication over windowed tensor \n",
    "            feature_map = np.dot(wind_img,kernel.flatten()[:,np.newaxis])\n",
    "\n",
    "            # reshape convolution feature map into array\n",
    "            feature_map = np.reshape(feature_map,(np.shape(image)))\n",
    "\n",
    "            # now shove result through nonlinear activation\n",
    "            feature_map = activation(feature_map)\n",
    "\n",
    "            #### now pool / downsample feature map, first window then pool on each window\n",
    "            wind_featmap = sliding_window_image(feature_map,kernel_size,stride = pool_stride)\n",
    "\n",
    "            # max pool on each collected patch\n",
    "            max_pool = np.max(wind_featmap,axis = 1)\n",
    "\n",
    "            # reshape into new tensor\n",
    "            max_pool = np.reshape(max_pool, (int((np.size(max_pool))**(0.5)),int((np.size(max_pool))**(0.5))))\n",
    "\n",
    "            # reshape into new downsampled pooled feature map\n",
    "            downsampled_feature_maps.append(max_pool)\n",
    "\n",
    "        ## re-shape downsampled_feature_maps and store\n",
    "        new_tensors.append(downsampled_feature_maps)\n",
    "\n",
    "    # reshape new tensor properly\n",
    "    new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1],np.shape(new_tensors)[2]*np.shape(new_tensors)[3]))\n",
    "    new_tensors = np.reshape(new_tensors, (np.shape(new_tensors)[0],np.shape(new_tensors)[1]*np.shape(new_tensors)[2]),order = 'F')\n",
    "    \n",
    "    return np.array(new_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A basic architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start by tacking on the convolution layer to our basic multilayer perceptron / feedforward architecture - i.e., no normalization of activation outputs, non-maxout activation, etc,.\n",
    "\n",
    "We simply need to change\n",
    "\n",
    "- input weights: we should include kernels now\n",
    "- before entering the fully connected network we pass our data (and kernels) through the convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fully evaluate our network features using the tensor of weights in omega_inner\n",
    "def compute_features(x, kernels,omega_inner):\n",
    "    #### NEW --- pass input data and kernels through convolutional layer #####\n",
    "    x_conv = conv_layer(x,kernels)\n",
    "    \n",
    "    #### pass result through fully connected multilayer perceptron ####\n",
    "    o = np.ones((np.shape(x_conv)[0],1))\n",
    "    a_padded = np.concatenate((o,x_conv),axis = 1)\n",
    "    \n",
    "    # loop through each layer matrix\n",
    "    for W in omega_inner:\n",
    "        # output of layer activation\n",
    "        a = activation(np.dot(a_padded,W))\n",
    "                \n",
    "        #  pad with ones (to compactly take care of bias) for next layer computation\n",
    "        o = np.ones((np.shape(a)[0],1))\n",
    "        a_padded = np.concatenate((o,a),axis = 1)\n",
    "        \n",
    "    return a_padded\n",
    "\n",
    "# our predict function \n",
    "def predict(x,omega):     \n",
    "    # compute network features - here omega[0] contains the entire tensor of internal weights\n",
    "    f = compute_features(x,omega[0],omega[1])\n",
    "    \n",
    "    # compute linear model compactly via inner product - here omega[1] contains only those weights in the final linear combination of network features\n",
    "    vals = np.dot(f,omega[2])\n",
    "    return vals\n",
    "\n",
    "# the softmax cost function written more compactly\n",
    "def softmax(w):\n",
    "    cost  = np.sum(np.log(1 + np.exp((-y)*(predict(x,w)))))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initialization has to be adjusted equivalently - we need to initialize kernels!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand what size our initial input layer must have we can pass our data and test kernels through the convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set number of kernels and kernel size, and pass a test set of kernels and data through the convolutional layer\n",
    "num_kernels = 2\n",
    "kernel_size = 3\n",
    "scale = 0.1\n",
    "kernels = np.random.randn(num_kernels,kernel_size,kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# push data and kernels through conv-layer\n",
    "x_convolved = conv_layer(x,kernels)\n",
    "L1 = np.shape(x_convolved)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With layer 1 size determined, we can now initialize our network ``layer_sizes``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_general_network_weights(num_kernels,kernel_size,layer_sizes,scale):\n",
    "    # container for entire weight tensor\n",
    "    weights = []\n",
    "    kernel_weights = []\n",
    "\n",
    "    # loop over desired kernel sizes and create appropriately sized initial \n",
    "    # weight matrix for each kernel\n",
    "    for k in range(num_kernels):\n",
    "        # make weight matrix\n",
    "        weight = scale*np.random.randn(kernel_size,kernel_size)\n",
    "        kernel_weights.append(weight)\n",
    "    kernel_weights = np.asarray(kernel_weights)\n",
    "\n",
    "    # loop over desired layer sizes and create appropriately sized initial \n",
    "    # weight matrix for each layer\n",
    "    for k in range(len(layer_sizes)-1):\n",
    "        # get layer sizes for current weight matrix\n",
    "        U_k = layer_sizes[k]\n",
    "        U_k_plus_1 = layer_sizes[k+1]\n",
    "\n",
    "        # make weight matrix\n",
    "        weight = scale*np.random.randn(U_k + 1,U_k_plus_1)\n",
    "        weights.append(weight)\n",
    "\n",
    "    # re-express weights so that w_init[0] = omega_inner contains all \n",
    "    # internal weight matrices, and w_init[1] = w contains weights of \n",
    "    # final linear combination in predict function\n",
    "    w_init = [kernel_weights,weights[:-1],weights[-1]]\n",
    "    return w_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can initialize weights for this network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_sizes\n",
    "num_kernels = 2\n",
    "kernel_size = 3\n",
    "scale = 0.1\n",
    "layer_sizes = [L1,5,1]\n",
    "w_init = initialize_general_network_weights(num_kernels,kernel_size,layer_sizes,scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test out our initialization by passing it and our data through the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10518486],\n",
       "       [ 0.10027592],\n",
       "       [ 0.09576042],\n",
       "       [ 0.10333978],\n",
       "       [ 0.09782135],\n",
       "       [ 0.08641705],\n",
       "       [ 0.11559694],\n",
       "       [ 0.14429247],\n",
       "       [ 0.13310843],\n",
       "       [ 0.08974176]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(x,w_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.1521834774557522"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(w_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from autograd import grad as compute_grad   \n",
    "test_grad = compute_grad(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ArrayBox' object has no attribute 'exp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3a9ea2f06364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36mnary_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0munary_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munary_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnary_op_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnary_op_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnary_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnary_operator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/autograd/differential_operators.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0marguments\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgradient\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     should be scalar-valued. The gradient has the same type as the argument.\"\"\"\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mvjp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         raise TypeError(\"Grad only applies to real scalar-output functions. \"\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/autograd/core.py\u001b[0m in \u001b[0;36mmake_vjp\u001b[0;34m(fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mstart_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVJPNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mend_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mvspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(start_node, fun, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mstart_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mend_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_box\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstart_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/autograd/wrap_util.py\u001b[0m in \u001b[0;36munary_f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0msubargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubvals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msubargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-ff8a6fe1d5f4>\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# the softmax cost function written more compactly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mcost\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_node\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m     \u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0margnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margnum\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m   \u001b[0;32min\u001b[0m \u001b[0mboxed_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Nurgetson/anaconda/lib/python3.5/site-packages/autograd/tracer.py\u001b[0m in \u001b[0;36mf_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnew_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_raw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mf_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_autograd_primitive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ArrayBox' object has no attribute 'exp'"
     ]
    }
   ],
   "source": [
    "wa = test_grad(w_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learned convolution features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in data - for this one split up training and testing\n",
    "ind = np.random.permutation(len(new_data))\n",
    "\n",
    "# split it up\n",
    "data_train = new_data[ind[:3],:]\n",
    "data_test = new_data[ind[3:],:]\n",
    "\n",
    "# load data into network\n",
    "demo = convlib.network_learner.Network()\n",
    "demo.input_data(data_train,data_test,normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# choose cost function\n",
    "demo.choose_cost(cost_name = 'twoclass_softmax')\n",
    "\n",
    "# setup network architecture\n",
    "activation_name = 'linear'\n",
    "num_kernels = 1\n",
    "layer_sizes = [64,2,1]\n",
    "demo.architecture_settings(activation_name,layer_sizes,num_kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup optimizer\n",
    "demo.optimizer_settings(alpha = 10**(-1),max_its = 10,version = 'unnormalized',scale = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# demo.fit(verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # compute cost plots on training and testing data\n",
    "# demo.compute_cost_plots()\n",
    "\n",
    "# # produce cost functio plots for training and testing data\n",
    "# demo.plot_histories(start = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# demo.weight_history[6]\n",
    "# demo.w_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# just the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 65)\n",
      "(65, 2)\n",
      "(1, 65, 2)\n",
      "Autograd ArrayBox with value [[-0.12022168 -0.13153025]\n",
      " [-0.03854317 -0.18003865]\n",
      " [-0.12064693 -0.33380425]]\n"
     ]
    }
   ],
   "source": [
    "test_grad = compute_grad(demo.training_cost)\n",
    "wa = test_grad(demo.w_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.08748114, -0.05287551, -0.12917575],\n",
       "        [-0.02690774,  0.05879566, -0.03019546],\n",
       "        [ 0.00932586,  0.16003246,  0.02650719]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.w_init[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([[ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.],\n",
       "         [ 0.,  0.]])],\n",
       " array([[[ -7.15182641e-03,  -7.07080660e-03,   7.15184790e-03],\n",
       "         [ -2.61320083e-05,  -1.23356751e-05,   7.15199310e-03],\n",
       "         [ -1.22775323e-05,  -1.21911916e-05,   7.15202422e-03]]]),\n",
       " array([[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]])]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.09398295,  0.06761082,  0.0184683 ],\n",
       "        [-0.19839479,  0.12737906, -0.04069006],\n",
       "        [ 0.03058614, -0.02851461, -0.10171031]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.w_init[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 784)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(demo.x_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

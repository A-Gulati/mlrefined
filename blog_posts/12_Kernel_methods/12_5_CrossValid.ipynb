{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 12: Kernel methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.5  Cross-validating kernel based learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general there is an large difference between the capacity of subsequent degrees $D$ and $D+1$ polynomial and Fourier kernels.  Take for instance the polynomial kernel.  Given the number of polynomial units $B$ encapsulated in a degree $D$ polynomial kernel (according to our calculations in Section 12.1.3) there are, for example, $20,958,500$ more polynomial units encapsulated in a degree $D=3$ kernel matrix than a degree $D=2$ kernel when $N=500$.  Because of this enormous leap in capacity between subsequent degree kernels cross-validation via *regularization* with the $\\ell_2$ norm, as detailed in Section 11.4, is common practice.  Since the hyperparameter of $\\gamma$ of the RBF kernel is continuous models employing it can - in addition to the regularization approach - be cross-validated in principle by comparing various values of $\\gamma$ directly.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 13: Multi-layer Perceptrons "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.6 The Backpropogation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The *backpropogation algorithm*, often referred to simply as *backpropogation* or *backprop* for short, is the jargon phrase used in machine learning to describe an approach to computing gradients that is especially effective for model's employing multi-layer perceptron units\n",
    "\n",
    "\n",
    "- This algorithm for gradient computing is easily programmable, lifting the tedious burden of computing gradients 'by hand', and allows for the construction of effective gradient calculators - often called *automatic differentiators* - that make computing gradients of virtually any cost function an easy chore\n",
    "\n",
    "\n",
    "- Indeed this is the main algorithm employed by the *automatic differentiator* software `autograd` we recommend using throughout this text\n",
    "\n",
    "\n",
    "- Like many technical advances throughout history, automatic differentiation was discovered and re-discovered by different researchers in different areas of science and engineering at different times.  This is precisely why this universally applicable concept - automatic differentiation - is referred to as *backpropogation* in the machine learning community, as this was the name given to it by its discoveres in this field.\n",
    "\n",
    "\n",
    "- In this Section we provide a high level overview of the backpropogation algorithm, and what makes it an especially effective gradient calculator for models employing multi-layer perceptron units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# some standard imports\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import matplotlib.pyplot as plt\n",
    "import autograd.numpy as np\n",
    "from autograd import grad as compute_grad   \n",
    "from autograd.misc.flatten import flatten_func\n",
    "from mlrefined_libraries import multilayer_perceptron_library as mlplib\n",
    "\n",
    "# This is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

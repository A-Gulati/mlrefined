{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The value of kernelization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real value of kernelizing any cost function is that for many fixed feature maps, including polynomials and Fourier features, the kernel matrix $\\mathbf{H}$ may be constructed without first building the matrix $\\mathbf{F}$, that is we need not construct it explicitly as $\\mathbf{H}=\\mathbf{F}^T\\mathbf{F}$, but this matrix may be constructed entry-wise via simple formulae. In fact, as we will see, thinking about constructing kernel matrices in this way leads to the construction of fixed feature bases by defining the kernel matrix first (that is, not by beginning with an explicit feature transformation). As we see in the next section this can be done for both degree $D$ polynomial and Fourier feature bases, as well as many other fixed maps. This is highly advantageous since, as discussed previously, even with moderate sized input dimension $N$ the dimension of a fixed feature transformation $M$ will likely be gargantuan, so large that we may not even be able to store the matrix $\\mathbf{F}$, let alone compute with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, note that the non-bias optimization variable from the original to kernelized form has changed from $\\mathbf{w}$, which had dimension $M$ in Equation (4), to $\\mathbf{z}$, which has dimension $P$ in the kernelized version shown in Equation (8). This is precisely how the dimension of the non-bias optimization variable changes with kernelized cost functions as well, like those shown in Table 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is true that for large datasets (that is large values of $P$, e.g., in the thousands or tens of thousands) the minimization of a kernelized cost function becomes more challenging, the main obstacle is storing the $P \\times P$ kernel matrix itself, which for large values of $P$ is difficult or even impossible to do completely. For example, with $P=10,000$ the corresponding kernel matrix will be of size $10,000 \\times 10,000$, with $10^8$ values to store, far more than a modern computer can store all at once. Moreover, the amount of computation required to perform, e.g. gradient descent, grows dramatically with the size of a kernel matrix due to its explosive size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common ways of dealing with these issues for large datasets include: 1) using advanced first order methods such as stochastic gradient descent, discussed in Chapter 13, so that only a small number of the kernelized points are dealt with at a time when optimizing; 2) reducing the dimension of data using techniques like Principal Component Analysis and hence avoiding the need for kernelized versions of fixed bases; 3) using the explicit structure of certain problems (see e.g., [[1,2]](#bib_cell)); and 4) employing the tools from function approximation to avoid explicit construction of the kernel matrix [[3,4,5]](#bib_cell))."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "197px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

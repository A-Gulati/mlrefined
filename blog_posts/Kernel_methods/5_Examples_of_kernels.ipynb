{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we present a list of examples of kernels for popular fixed feature transformations that may be built without first constructing the explicit feature transformation itself. While these are the most commonly used kernels in practice, the reader can see e.g., [[6,7]](#bib_cell)) for a more exhaustive list of kernels and their properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 1. </span> The polynomial kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following second degree polynomial mapping from $N=2$ to $M=5$ dimensional space given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{f}\\left(\\left[\\begin{array}{c}\n",
    "x_{1}\\\\\n",
    "x_{2}\n",
    "\\end{array}\\right]\\right)=\\left[\\begin{array}{ccccc}\n",
    "\\sqrt{2}x_{1}^{\\,} & \\sqrt{2}x_{2}^{\\,} & x_{1}^{2} & \\sqrt{2}x_{1}^{\\,}x_{2}^{\\,} & x_{2}^{2}\\end{array}\\right]^{T}\n",
    "\\end{equation}\n",
    "\n",
    "This is entirely equivalent to a standard degree $2$ polynomial, as the $\\sqrt{2}$ attached to several of the terms can be absorbed by their associated weights when taking the corresponding weighted sum $\\underset{m=1}{\\overset{5}{\\sum}}f_{m}\\left(\\mathbf{x}\\right)w_{m}$.\n",
    "\n",
    "Denoting briefly by $\\mathbf{u}=\\mathbf{x}_{i}$ and $\\mathbf{v}=\\mathbf{x}_{j}$\n",
    "the $i^{\\textrm{th}}$ and $j^{\\textrm{th}}$ input data points respectively,\n",
    "the $\\left(i,j\\right)^{\\textrm{th}}$ element of the kernel matrix\n",
    "for a degree 2 polynomial $\\mathbf{H}=\\mathbf{F}^{T}\\mathbf{F}$ may\n",
    "be written as\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{array}{c}\n",
    "\\mathbf{H}_{ij}=\\left[\\begin{array}{ccccc}\n",
    "\\sqrt{2}u_{1} & \\sqrt{2}u_{2} & u_{1}^{2} & \\sqrt{2}u_{1}u_{2} & u_{2}^{2}\\end{array}\\right]\\left[\\begin{array}{c}\n",
    "\\sqrt{2}v_{1}\\\\\n",
    "\\sqrt{2}v_{2}\\\\\n",
    "v_{1}^{2}\\\\\n",
    "\\sqrt{2}v_{1}v_{2}\\\\\n",
    "v_{2}^{2}\n",
    "\\end{array}\\right]\\end{array}\n",
    "\\\\\n",
    "=\\left(1+2u_{1}v_{1}+2u_{2}v_{2}+u_{1}^{2}v_{1}^{2}+2u_{1}u_{2}v_{1}v_{2}+u_{2}^{2}v_{2}^{2}\\right)-1\n",
    "\\\\\n",
    "=\\left(1+u_{1}v_{1}+u_{2}v_{2}\\right)^{2}-1=\\left(1+\\mathbf{u}^{T}\\mathbf{v}\\right)^{2}-1\n",
    "\\end{equation}\n",
    "\n",
    "In short, the *polynomial kernel* matrix $\\mathbf{H}$ may be built without first constructing the explicit features in Equation (10), and may be simply defined\n",
    "entry-wise as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{ij}=\\left(1+\\mathbf{x}_{i}^{T}\\mathbf{x}_{j}\\right)^{2}-1\n",
    "\\end{equation}\n",
    "\n",
    "Again note that with the polynomial kernel defined above we only require access to the original input data, not the explicit polynomial features themselves.\n",
    "\n",
    "Although the kernel construction rule in Equation (12) was derived specifically for $N=2$ and a degree two polynomial, one can show that a polynomial kernel can be defined entry-wise for general $N$ and degree $D$ analogously as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{ij}=\\left(1+\\mathbf{x}_{i}^{T}\\mathbf{x}_{j}\\right)^{D}-1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 2. </span>  The Fourier kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree $D$ Fourier feature transformation from $N=1$ to $M=2D$ dimensional\n",
    "space is given as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{f}_{p}=\\left[\\begin{array}{ccccc}\n",
    "\\sqrt{2}\\mbox{cos}\\left(2\\pi x_{p}\\right) & \\sqrt{2}\\mbox{sin}\\left(2\\pi x_{p}\\right) & \\cdots & \\sqrt{2}\\mbox{cos}\\left(2D\\pi x_{p}\\right) & \\sqrt{2}\\mbox{sin}\\left(2D\\pi x_{p}\\right)\\end{array}\\right]^{T}\n",
    "\\end{equation}\n",
    "\n",
    "For a dataset of $P$ points the corresponding $\\left(i,j\\right)^{th}$\n",
    "element of the corresponding kernel matrix $\\mathbf{H}$ can be written\n",
    "as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{ij}=\\mathbf{f}_{i}^{T}\\mathbf{f}_{j}=2 \\sum_{m=1}^{D}\\mbox{cos}\\left(2\\pi mx_{i}\\right)\\mbox{cos}\\left(2\\pi mx_{j}\\right)+\\mbox{sin}\\left(2\\pi mx_{i}\\right)\\mbox{sin}\\left(2\\pi mx_{j}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Using trigonometric identities one can show (see Section \\ref{subsec:Fourier-kernel-calculations-scalar})\n",
    "that this may equivalently be written as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{ij}=\\frac{\\mbox{sin}\\left(\\left(2D+1\\right)\\pi\\left(x_{i}-x_{j}\\right)\\right)}{\\mbox{sin}\\left(\\pi\\left(x_{i}-x_{j}\\right)\\right)}-1.\n",
    "\\end{equation}\n",
    "\n",
    "Note that whenever $x_{i}-x_{j}$ is integer valued the term $\\frac{\\text{sin}\\left(\\left(2D+1\\right)\\pi\\left(x_{i}-x_{j}\\right)\\right)}{\\text{sin}\\left(\\pi\\left(x_{i}-x_{j}\\right)\\right)}$\n",
    "is not technically defined. In these case it is simply replaced by\n",
    "its associated limit which, regardless of the integer value $x_{i}-x_{j}$,\n",
    "is always equal to $2D+1$ meaning that $\\mathbf{H}_{ij}=2D$. \n",
    "\n",
    "Moreover for general $N$ dimensional input the corresponding kernel\n",
    "can be written similarly entry-wise as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{ij}=\\underset{n=1}{\\overset{N}{\\prod}}\\frac{\\mbox{sin}\\left(\\left(2D+1\\right)\\pi\\left(x_{in}-x_{jn}\\right)\\right)}{\\mbox{sin}\\left(\\pi\\left(x_{in}-x_{jn}\\right)\\right)}-1.\n",
    "\\end{equation}\n",
    "\n",
    "As with the one dimensional version whenever $x_{in}-x_{jn}$ is integer\n",
    "valued the associated term $\\frac{\\mbox{sin}\\left(\\left(2D+1\\right)\\pi\\left(x_{in}-x_{jn}\\right)\\right)}{\\mbox{sin}\\left(\\pi\\left(x_{in}-x_{jn}\\right)\\right)}$\n",
    "in the product is replaced by its limit which, regardless of the value\n",
    "of $x_{in}-x_{jn}$, is always equal to $2D+1$. See Section \\ref{subsec:Fourier-kernel-calculations-vector-input}\n",
    "for further details.\n",
    "\n",
    "With this formula we may compute the degree $D$ Fourier features\n",
    "for arbitrary $N$ dimensional input vectors without calculating the\n",
    "enormous number (see footnote \\ref{fn:high-dim-fourier-basis}) of\n",
    "basis features explicitly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:#a50e3e;\">Example 3. </span>  Kernel representation of radial basis function (RBF) features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another popular choice of kernel is the\\emph{ radial basis function\n",
    "}(RBF) kernel which is typically defined explicitly as a kernel matrix\n",
    "over the input data as\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{ij}=e^{-\\beta\\left\\Vert \\mathbf{x}_{i}-\\mathbf{x}_{j}\\right\\Vert _{2}^{2}}\n",
    "\\end{equation}\n",
    "\n",
    "Here the kernel parameter $\\beta$ is tuned to the data in practice\n",
    "via cross-validation. \n",
    "\n",
    "While the RBF kernel is typically defined directly as above, it can be traced back to an explicit fixed feature basis as with the polynomial and Fourier kernels i.e., we have that\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{H}_{ij}=\\mathbf{f}_{i}^{T}\\mathbf{f}_{j},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{f}_{i}$ is the fixed feature transformation of the input $\\mathbf{x}_{i}$ based on a fixed basis. While the length of a feature transformation corresponding to a degree $D$ polynomial/Fourier kernel matrix can be extremely large (as discussed in the introduction to this Section), with the RBF kernel the associated feature transformation is always \\emph{infinite }dimensional. For example when $N=1$ the feature vector $\\mathbf{f}_{i}$ takes the form $\\mathbf{f}_{i}=\\left[\\begin{array}{cccc}\n",
    "f_{1}\\left(x_{i}\\right) & f_{2}\\left(x_{i}\\right) & f_{3}\\left(x_{i}\\right) & \\cdots\\end{array}\\right]^{T}$, where the $m^{th}$ fixed basis feature is defined as\n",
    "\n",
    "\\begin{equation}\n",
    "f_{m}\\left(x_{i}\\right)=e^{-\\beta x_{i}^{2}}\\sqrt{\\frac{\\left(2\\beta\\right)^{m-1}}{\\left(m-1\\right)!}}x_{i}^{m-1}\\quad\\textrm{for all }m\\geq1\n",
    "\\end{equation}\n",
    "\n",
    "When $N>1$ the corresponding feature vector takes on an analogous form (and is also infinite in length), but regardless of the input dimension it would impossible to even construct and store a single $\\mathbf{f}_{i}$ let alone such transformations of the entire dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polynomial, Fourier, and RBF kernel matrices introduced earlier are all similarity matrices, essentially encoding how close or similar a collection of data points are to one another, with points in proximity to one another receiving a high value and those far apart receiving a low value. In this sense all three kernels discussed here, and hence all three corresponding fixed feature bases, define some kind of similarity between data points xi and xj from different geometric perspectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Figure \\ref{fig:kernels} we compare these three kernels geometrically\n",
    "by fixing a point $\\mathbf{x}_{p}=\\left[\\begin{array}{cc}\n",
    "0.5 & 0.5\\end{array}\\right]^{T}$ and plotting $\\mathbf{H}\\left(\\mathbf{x},\\mathbf{x}_{p}\\right)$\n",
    "over the range $\\mathbf{x}\\in\\left[0,1\\right]^{2}$, producing a color-coded\n",
    "surface showing how each kernel treats points near $\\mathbf{x}_{p}$.\n",
    "Analyzing this Figure we can judge more generally how the three kernels\n",
    "define 'similarity' between points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <img src= '../../mlrefined_images/kernel_images/Fig_7_2.png' width=\"80%\"/>\n",
    "  <figcaption> \n",
    "      <strong>Figure 2:</strong> \n",
    "      <em> \n",
    "Surfaces generated by polynomial, Fourier, and RBF kernels centered at xp =   0.5 0.5  T with the surfaces color-coded based on their similarity to xp. (left panel) A degree 2 polynomial kernel, (middle panel) degree 3 Fourier kernel, and (right panel) RBF kernel with β = 10. See text for further details.\n",
    "      </em>\n",
    "  </figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we can see that a polynomial kernel treats data points xi and xj similarly if their inner product is high or, in other words, they highly correlate with each other. Likewise the points are treated as dissimilar when they are orthogonal to one another. On the other hand, the Fourier kernel treats points as similar if they lie close together, but their similarity differs like a “sinc” function as their distance from each other grows. Finally an RBF kernel provides a smooth similarity between points. If they are close to each other in a Euclidean sense they are highly similar; however, once the distance between them passes a certain threshold they are deemed rapidly dissimilar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "197px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

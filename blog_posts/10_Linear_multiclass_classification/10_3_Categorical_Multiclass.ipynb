{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 10 Linear multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  10.3  Categorical multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This code cell will not be shown in the HTML version of this notebook\n",
    "# import custom library\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from mlrefined_libraries import superlearn_library as superlearn\n",
    "from mlrefined_libraries import math_optimization_library as optlib\n",
    "optimizers = optlib.optimizers\n",
    "classif_plotter = superlearn.multi_lin_classification_demo\n",
    "cost_lib = superlearn.cost_functions\n",
    "normalizers = superlearn.normalizers \n",
    "datapath = '../../mlrefined_datasets/superlearn_datasets/'\n",
    "\n",
    "# standard imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import autograd-wrapped numpy\n",
    "import autograd.numpy as np\n",
    "\n",
    "# this is needed to compensate for matplotlib notebook's tendancy to blow up images when plotted inline\n",
    "%matplotlib notebook\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.autolayout'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One often sees this cost function go by many names - e.g., *softmax regression* and *multi-class logistic regression* - for as with two-class classification the softmax cost can be interpreted from a logistic regression (surface fitting) perspective. One also often sees the cost written in various ways in practice as well - sometimes due to the perspective taken in deriving it, or for numerical stability reasons. A very common alternative way one will see the softmax multi-class cost function written (when thought of from the perspective of logistic regression) can be seen by using basic properties of the log function. Using the following properties \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{log}\\left(s\\cdot t\\right) = \\text{log}\\left(s\\right) + \\text{log}\\left(t\\right) \\\\\n",
    "\\text{log}\\left(s\\right)^{-1} = \\text{log}\\left(\\frac{1}{s}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "one can express the softmax multi-class cost in equation (10) equivalently as\n",
    "\n",
    "\\begin{equation}\n",
    "g\\left(w_0^{(0)},\\,\\mathbf{w}_{\\mathstrut}^{(0)},...,w_0^{(C-1)},\\,\\mathbf{w}_{\\mathstrut}^{(C-1)} \\right) = -\\frac{1}{P}\\sum_{p = 1}^P \\text{log}\\left(\\frac{ e^{ w_0^{(y_p)} + \\mathbf{x}_{p}^T\\mathbf{w}_{\\mathstrut}^{(y_p)}} }{ \\sum_{j = 0}^{C-1}  e^{ w_0^{(j)} + \\mathbf{x}_{p}^T\\mathbf{w}_{\\mathstrut}^{(j)}} }\\right)\n",
    "\\end{equation}\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# multiclass softmaax regularized by the summed length of all normal vectors\n",
    "lam = 10**(-5)  # our regularization paramter \n",
    "def multiclass_softmax(w):        \n",
    "    # pre-compute predictions on all points\n",
    "    all_evals = model(x,w)\n",
    "    \n",
    "    # compute softmax across data points\n",
    "    a = np.log(np.sum(np.exp(all_evals),axis = 0)) \n",
    "    \n",
    "    # compute cost in compact form using numpy broadcasting\n",
    "    b = all_evals[y.astype(int).flatten(),np.arange(np.size(y))]\n",
    "    cost = np.sum(a - b)\n",
    "    \n",
    "    # add regularizer\n",
    "    cost = cost + lam*np.linalg.norm(w[1:,:],'fro')**2\n",
    "    \n",
    "    # return average\n",
    "    return cost/float(np.size(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "230px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
